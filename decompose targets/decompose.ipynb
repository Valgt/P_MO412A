{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar spaCy y descargar el modelo de inglés\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# Instalar SentenceTransformers para embeddings semánticos\n",
    "# !pip install sentence-transformers\n",
    "\n",
    "# Instalar NLTK para manejo de sinónimos\n",
    "# !pip install nltk\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV cargado exitosamente.\n",
      "\n",
      "Se han extraído 19 textos para el goal_id 17.\n",
      "\n",
      "Lista 'targets':\n",
      "1. Strengthen domestic resource mobilization, including through international support to developing countries, to improve domestic capacity for tax and other revenue collection | Total government revenue as a proportion of GDP, by source | Proportion of domestic budget funded by domestic taxes\n",
      "\n",
      "2. Developed countries to implement fully their official development assistance commitments, including the commitment by many developed countries to achieve the target of 0.7 per cent of ODA/GNI to developing countries and 0.15 to 0.20 per cent of ODA/GNI to least developed countries; ODA providers are encouraged to consider setting a target to provide at least 0.20 per cent of ODA/GNI to least developed countries | Net official development assistance, total and to least developed countries, as a proportion of the Organization for Economic Cooperation and Development (OECD) Development Assistance Committee donors' gross national income (GNI)\n",
      "\n",
      "3. Mobilize additional financial resources for developing countries from multiple sources | Foreign direct investments (FDI), official development assistance and South- South Cooperation as a proportion of total domestic budget | Volume of remittances (in United States dollars) as a proportion of total GDP\n",
      "\n",
      "4. Assist developing countries in attaining long-term debt sustainability through coordinated policies aimed at fostering debt financing, debt relief and debt restructuring, as appropriate, and address the external debt of highly indebted poor countries to reduce debt distress | Debt service as a proportion of exports of goods and services\n",
      "\n",
      "5. Adopt and implement investment promotion regimes for least developed countries  | Number of countries that adopt and implement investment promotion regimes for least developed countries\n",
      "\n",
      "6. Enhance North-South, South-South and triangular regional and international cooperation on and access to science, technology and innovation and enhance knowledge sharing on mutually agreed terms, including through improved coordination among existing mechanisms, in particular at the United Nations level, and through a global technology facilitation mechanism | Number of science and/or technology cooperation agreements and programmes between countries, by type of cooperation | Fixed Internet broadband subscriptions per 100 inhabitants, by speed\n",
      "\n",
      "7. Promote the development, transfer, dissemination and diffusion of environmentally sound technologies to developing countries on favourable terms, including on concessional and preferential terms, as mutually agreed | Total amount of approved funding for developing countries to promote the development, transfer, dissemination and diffusion of environmentally sound technologies\n",
      "\n",
      "8. Fully operationalize the technology bank and science, technology and innovation capacity-building mechanism for least developed countries by 2017 and enhance the use of enabling technology, in particular information and communications technology  | Proportion of individuals using the Internet\n",
      "\n",
      "9. Enhance international support for implementing effective and targeted capacity-building in developing countries to support national plans to implement all the sustainable development goals, including through North-South, South-South and triangular cooperation  | Dollar value of financial and technical assistance (including through North-South, South-South and triangular cooperation) committed to developing countries\n",
      "\n",
      "10. Promote a universal, rules-based, open, non-discriminatory and equitable multilateral trading system under the World Trade Organization, including through the conclusion of negotiations under its Doha Development Agenda | Worldwide weighted tariff- average\n",
      "\n",
      "11. Significantly increase the exports of developing countries, in particular with a view to doubling the least developed countries’ share of global exports by 2020 | Developing countries' and least developed countries' share of global exports\n",
      "\n",
      "12. Realize timely implementation of duty-free and quota-free market access on a lasting basis for all least developed countries, consistent with World Trade Organization decisions, including by ensuring that preferential rules of origin applicable to imports from least developed countries are transparent and simple, and contribute to facilitating market access  | Average tariffs faced by developing countries, least developed countries and small island developing States\n",
      "\n",
      "13. Enhance global macroeconomic stability, including through policy coordination and policy coherence | Macroeconomic Dashboard\n",
      "\n",
      "14. Enhance policy coherence for sustainable development | Number of countries with mechanisms in place to enhance policy coherence of sustainable development\n",
      "\n",
      "15. Respect each country’s policy space and leadership to establish and implement policies for poverty eradication and sustainable development | Extent of use of country-owned results frameworks and planning tools by providers of development cooperation\n",
      "\n",
      "16. Enhance the global partnership for sustainable development, complemented by multi-stakeholder partnerships that mobilize and share knowledge, expertise, technology and financial resources, to support the achievement of the sustainable development goals in all countries, in particular developing countries | Number of countries reporting progress in multi-stakeholder development effectiveness monitoring frameworks that support the achievement of the sustainable development goals\n",
      "\n",
      "17. Encourage and promote effective public, public-private and civil society partnerships, building on the experience and resourcing strategies of partnerships | Amount of United States dollars committed to public-private and civil society partnerships\n",
      "\n",
      "18. By 2020, enhance capacity-building support to developing countries, including for least developed countries and small island developing States, to increase significantly the availability of high-quality, timely and reliable data disaggregated by income, gender, age, race, ethnicity, migratory status, disability, geographic location and other characteristics relevant in national contexts | Proportion of sustainable development indicators produced at the national level with full disaggregation when relevant to the target, in accordance with the Fundamental Principles of Official Statistics | Number of countries that have national statistical legislation that complies with the Fundamental Principles of Official Statistics | Number of countries with a national statistical plan that is fully funded and under implementation, by source of funding\n",
      "\n",
      "19. By 2030, build on existing initiatives to develop measurements of progress on sustainable development that complement gross domestic product, and support statistical capacity-building in developing countries  | Dollar value of all resources made available to strengthen statistical capacity in developing countries | Proportion of countries that (a) have conducted at least one population and housing census in the last 10 years; and (b) have achieved 100 per cent birth registration and 80 per cent death registration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Nombre del archivo CSV generado previamente\n",
    "archivo_csv = 'SDG_final.csv'\n",
    "\n",
    "# Definir el goal_id fijo\n",
    "goal_id_fijo = '17'  # Cambia este valor según el GOAL que desees (por ejemplo, '2', '3', etc.)\n",
    "\n",
    "try:\n",
    "    # Cargar el archivo CSV\n",
    "    df = pd.read_csv(archivo_csv, delimiter=',', encoding='utf-8')\n",
    "    print(\"Archivo CSV cargado exitosamente.\\n\")\n",
    "    \n",
    "    # Verificar que las columnas necesarias existen en el DataFrame\n",
    "    columnas_necesarias = {'goal_id', 'target_id', 'texto'}\n",
    "    if not columnas_necesarias.issubset(df.columns):\n",
    "        missing = columnas_necesarias - set(df.columns)\n",
    "        raise KeyError(f\"Faltan las siguientes columnas en el archivo CSV: {missing}\")\n",
    "    \n",
    "    # Filtrar las filas que corresponden al goal_id especificado\n",
    "    df_goal = df[df['goal_id'].astype(str) == str(goal_id_fijo)]\n",
    "    \n",
    "    # Verificar si se encontraron filas para el goal_id especificado\n",
    "    if df_goal.empty:\n",
    "        print(f\"No se encontraron registros para el goal_id '{goal_id_fijo}'.\")\n",
    "    else:\n",
    "        # Extraer la columna 'texto' y almacenarla en una lista llamada 'targets'\n",
    "        targets = df_goal['texto'].tolist()\n",
    "        goal_ids = df_goal['goal_id'].tolist()\n",
    "        target_ids = df_goal['target_id'].tolist()\n",
    "        \n",
    "        # Mostrar la cantidad de textos extraídos\n",
    "        print(f\"Se han extraído {len(targets)} textos para el goal_id {goal_id_fijo}.\\n\")\n",
    "        \n",
    "        # Mostrar los textos extraídos\n",
    "        print(\"Lista 'targets':\")\n",
    "        for idx, texto in enumerate(targets, start=1):\n",
    "            print(f\"{idx}. {texto}\\n\")\n",
    "        \n",
    "        # (Opcional) Guardar la lista 'targets' en un archivo de texto\n",
    "        # Descomenta las siguientes líneas si deseas guardar los textos en un archivo\n",
    "        \"\"\"\n",
    "        nombre_archivo_salida = f'targets_goal_{goal_id_fijo}.txt'\n",
    "        with open(nombre_archivo_salida, 'w', encoding='utf-8') as f:\n",
    "            for texto in targets:\n",
    "                f.write(texto + '\\n')\n",
    "        print(f\"Lista 'targets' guardada en el archivo '{nombre_archivo_salida}'.\")\n",
    "        \"\"\"\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo '{archivo_csv}' no se encontró en el directorio actual.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: El archivo '{archivo_csv}' está vacío.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"Error: El archivo '{archivo_csv}' no pudo ser parseado. Verifica el delimitador y el formato del archivo.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error de clave: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'Compiled-Keywords-for-SDG-2.csv' cargado exitosamente.\n",
      "\n",
      "Lista 'palabras_clave' para la columna 'SDG 17' y 'Misc':\n",
      "\n",
      "1. Capacity building\n",
      "2. Civil society partnerships\n",
      "3. Communication technologies\n",
      "4. Debt sustainability\n",
      "5. Development assistance\n",
      "6. Disaggregated data\n",
      "7. Doha Development Agenda\n",
      "8. Entrepreneurship\n",
      "9. Environmentally sound technologies\n",
      "10. Foreign direct investments\n",
      "11. Fostering innovation\n",
      "12. Free trade\n",
      "13. Fundamental principles of official statistics\n",
      "14. Global partnership\n",
      "15. Global partnership for sustainable development\n",
      "16. Global stability\n",
      "17. International aid\n",
      "18. International cooperation\n",
      "19. International population and housing census\n",
      "20. International support\n",
      "21. International support for developing countries\n",
      "22. Knowledge sharing\n",
      "23. Multi-stakeholder partnerships\n",
      "24. Poverty eradication\n",
      "25. Public-private partnerships\n",
      "26. Science cooperation agreements\n",
      "27. Technology cooperation agreements\n",
      "28. Technology transfer\n",
      "29. Weighted tariff average\n",
      "30. Women entrepreneurs\n",
      "31. World Trade Organization\n",
      "32. Accountability\n",
      "33. Alternative energy\n",
      "34. Biodiversity\n",
      "35. Caring for country\n",
      "36. CO2 emissions\n",
      "37. Developing countries\n",
      "38. Disability\n",
      "39. Eco tourism\n",
      "40. Ecology\n",
      "41. Energy efficiency\n",
      "42. Environment\n",
      "43. Environmental\n",
      "44. Environmental degradation\n",
      "45. Environmental policy\n",
      "46. Environmental sustainability\n",
      "47. Equal rights to economic resources\n",
      "48. Ethical\n",
      "49. Food-energy-water nexus\n",
      "50. Water-energy-food nexus\n",
      "51. Forced displacement\n",
      "52. Good governance\n",
      "53. Governance\n",
      "54. Governance and policy\n",
      "55. Governance and risk\n",
      "56. Human rights\n",
      "57. Human well-being\n",
      "58. Inclusive\n",
      "59. Indigenous knowledge\n",
      "60. Inter-generational\n",
      "61. Irregular migration\n",
      "62. Kaitiakitanga\n",
      "63. Land locked developing countries\n",
      "64. Least developed countries\n",
      "65. Leave no one behind\n",
      "66. Low impact agriculture\n",
      "67. Low impact farming\n",
      "68. Low impact horticulture\n",
      "69. Migrant rights\n",
      "70. Migration and policy\n",
      "71. Policy coherence\n",
      "72. Pollution - Air\n",
      "73. Soil\n",
      "74. Water\n",
      "75. Promotion of shared responsibilities\n",
      "76. Recycling\n",
      "77. Refugee crisis\n",
      "78. Refugee rights\n",
      "79. Renewable\n",
      "80. Resilient\n",
      "81. Reuse technologies\n",
      "82. Small island developing states\n",
      "83. Smart cities\n",
      "84. Smart grid\n",
      "85. Smart houses\n",
      "86. Social protection policies\n",
      "87. Social responsibility\n",
      "88. Sustainability\n",
      "89. Sustainable\n",
      "90. Sustainable development\n",
      "91. Sustainable Development Goals\n",
      "92. Sustainable development indicators\n",
      "93. Sustainable management\n",
      "94. Sustainable public transport\n",
      "95. Sustainable societies\n",
      "96. Sustainable transport\n",
      "97. Technology for sustainable development\n",
      "98. Tele-working\n",
      "99. Transboundary cooperation\n",
      "100. Water sensitive revitalisation\n",
      "101. Well-being\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Nombre del archivo CSV\n",
    "archivo_csv = 'Compiled-Keywords-for-SDG-2.csv'\n",
    "\n",
    "# Definir el parámetro fijo X (por ejemplo, 'SDG 1')\n",
    "X = f'SDG {goal_id_fijo}'  # Cambia este valor según el GOAL que desees (e.g., 'SDG 2', 'SDG3', etc.)\n",
    "\n",
    "try:\n",
    "    # Cargar el archivo CSV\n",
    "    df = pd.read_csv(archivo_csv, delimiter=',', encoding='utf-8')\n",
    "    print(f\"Archivo '{archivo_csv}' cargado exitosamente.\\n\")\n",
    "    \n",
    "    # Verificar que las columnas X y 'Misc' existen en el DataFrame\n",
    "    columnas_necesarias = [X, 'Misc']\n",
    "    columnas_presentes = df.columns.tolist()\n",
    "    \n",
    "    for columna in columnas_necesarias:\n",
    "        if columna not in columnas_presentes:\n",
    "            raise KeyError(f\"La columna '{columna}' no existe en el archivo CSV. Columnas disponibles: {columnas_presentes}\")\n",
    "    \n",
    "    # Extraer las columnas X y 'Misc', eliminando valores nulos y espacios en blanco\n",
    "    elementos_X = df[X].dropna().astype(str).str.strip()\n",
    "    elementos_Misc = df['Misc'].dropna().astype(str).str.strip()\n",
    "    \n",
    "    # Combinar ambas series\n",
    "    combinados = pd.concat([elementos_X, elementos_Misc])\n",
    "    \n",
    "    # Eliminar entradas vacías después de stripping y convertir a lista de elementos únicos\n",
    "    combinados = combinados[combinados != '']\n",
    "    palabras_clave = combinados.unique().tolist()\n",
    "    \n",
    "    # Eliminar posibles duplicados adicionales y valores vacíos\n",
    "    palabras_clave = [elemento for elemento in palabras_clave if elemento]\n",
    "    \n",
    "    # Mostrar la lista 'palabras_clave'\n",
    "    print(f\"Lista 'palabras_clave' para la columna '{X}' y 'Misc':\\n\")\n",
    "    for idx, elemento in enumerate(palabras_clave, start=1):\n",
    "        print(f\"{idx}. {elemento}\")\n",
    "    \n",
    "    # (Opcional) Guardar la lista 'palabras_clave' en un archivo de texto\n",
    "    # Descomenta las siguientes líneas si deseas guardar los resultados\n",
    "    \"\"\"\n",
    "    nombre_archivo_salida = f'palabras_clave_{X.replace(\" \", \"_\")}_y_Misc.txt'\n",
    "    with open(nombre_archivo_salida, 'w', encoding='utf-8') as f:\n",
    "        for elemento in palabras_clave:\n",
    "            f.write(elemento + '\\n')\n",
    "    print(f\"\\nLa lista 'palabras_clave' ha sido guardada en el archivo '{nombre_archivo_salida}'.\")\n",
    "    \"\"\"\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo '{archivo_csv}' no se encontró en el directorio actual.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: El archivo '{archivo_csv}' está vacío.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"Error: El archivo '{archivo_csv}' no pudo ser parseado. Verifica el delimitador y el formato del archivo.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error de clave: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras clave normalizadas:\n",
      "['capacity building', 'civil society partnerships', 'communication technologies', 'debt sustainability', 'development assistance', 'disaggregated data', 'doha development agenda', 'entrepreneurship', 'environmentally sound technologies', 'foreign direct investments', 'fostering innovation', 'free trade', 'fundamental principles of official statistics', 'global partnership', 'global partnership for sustainable development', 'global stability', 'international aid', 'international cooperation', 'international population and housing census', 'international support', 'international support for developing countries', 'knowledge sharing', 'multistakeholder partnerships', 'poverty eradication', 'publicprivate partnerships', 'science cooperation agreements', 'technology cooperation agreements', 'technology transfer', 'weighted tariff average', 'women entrepreneurs', 'world trade organization', 'accountability', 'alternative energy', 'biodiversity', 'caring for country', 'co2 emissions', 'developing countries', 'disability', 'eco tourism', 'ecology', 'energy efficiency', 'environment', 'environmental', 'environmental degradation', 'environmental policy', 'environmental sustainability', 'equal rights to economic resources', 'ethical', 'foodenergywater nexus', 'waterenergyfood nexus', 'forced displacement', 'good governance', 'governance', 'governance and policy', 'governance and risk', 'human rights', 'human wellbeing', 'inclusive', 'indigenous knowledge', 'intergenerational', 'irregular migration', 'kaitiakitanga', 'land locked developing countries', 'least developed countries', 'leave no one behind', 'low impact agriculture', 'low impact farming', 'low impact horticulture', 'migrant rights', 'migration and policy', 'policy coherence', 'pollution air', 'soil', 'water', 'promotion of shared responsibilities', 'recycling', 'refugee crisis', 'refugee rights', 'renewable', 'resilient', 'reuse technologies', 'small island developing states', 'smart cities', 'smart grid', 'smart houses', 'social protection policies', 'social responsibility', 'sustainability', 'sustainable', 'sustainable development', 'sustainable development goals', 'sustainable development indicators', 'sustainable management', 'sustainable public transport', 'sustainable societies', 'sustainable transport', 'technology for sustainable development', 'teleworking', 'transboundary cooperation', 'water sensitive revitalisation', 'wellbeing']\n",
      "\n",
      "Primer target normalizado:\n",
      "strengthen domestic resource mobilization including through international support to developing countries to improve domestic capacity for tax and other revenue collection total government revenue as a proportion of gdp by source proportion of domestic budget funded by domestic taxes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    \"\"\"\n",
    "    Normaliza el texto:\n",
    "    - Convierte a minúsculas\n",
    "    - Elimina acentos\n",
    "    - Elimina caracteres especiales\n",
    "    - Elimina espacios en blanco excesivos\n",
    "    \"\"\"\n",
    "    # Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # Eliminar acentos\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    # Eliminar caracteres especiales\n",
    "    texto = re.sub(r'[^a-z0-9\\s]', '', texto)\n",
    "    # Eliminar espacios en blanco excesivos\n",
    "    texto = ' '.join(texto.split())\n",
    "    return texto\n",
    "\n",
    "# Normalizar palabras clave\n",
    "palabras_clave_normalizadas = [normalizar_texto(palabra) for palabra in palabras_clave]\n",
    "\n",
    "# Normalizar targets\n",
    "targets_normalizados = [normalizar_texto(target) for target in targets]\n",
    "\n",
    "print(\"Palabras clave normalizadas:\")\n",
    "print(palabras_clave_normalizadas)\n",
    "print(\"\\nPrimer target normalizado:\")\n",
    "print(targets_normalizados[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo conceptos: 100%|██████████| 19/19 [00:00<00:00, 103.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conceptos extraídos para el primer target:\n",
      "{'a proportion', 'source proportion', 'domestic budget', 'domestic taxes', 'domestic resource mobilization', 'international support', 'domestic capacity', 'developing countries', 'other revenue collection total government revenue'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargar el modelo de spaCy para inglés\n",
    "# Nota: Asegúrate de haber descargado el modelo 'en_core_web_sm' previamente\n",
    "# Puedes hacerlo ejecutando: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extraer_conceptos(target):\n",
    "    \"\"\"\n",
    "    Extrae conceptos clave de un target utilizando spaCy.\n",
    "    \"\"\"\n",
    "    doc = nlp(target)\n",
    "    conceptos = set()\n",
    "    for chunk in doc.noun_chunks:\n",
    "        # Filtrar chunks demasiado cortos\n",
    "        if len(chunk.text.split()) < 2:\n",
    "            continue\n",
    "        # Filtrar chunks que sean solo stop words\n",
    "        if all(token.is_stop for token in chunk):\n",
    "            continue\n",
    "        # Añadir el chunk normalizado\n",
    "        conceptos.add(normalizar_texto(chunk.text))\n",
    "    return conceptos\n",
    "\n",
    "# Extraer conceptos de todos los targets\n",
    "targets_conceptos = []\n",
    "for target in tqdm(targets_normalizados, desc=\"Extrayendo conceptos\"):\n",
    "    conceptos = extraer_conceptos(target)\n",
    "    targets_conceptos.append(conceptos)\n",
    "\n",
    "# Ejemplo de conceptos extraídos para el primer target\n",
    "print(\"\\nConceptos extraídos para el primer target:\")\n",
    "print(targets_conceptos[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras clave expandidad con sinónimos restringidos:\n",
      "['soil', 'free trade', 'social responsibility', 'sustainable', 'intergenerational', 'least developed countries', 'smart grid', 'sustainable development', 'women entrepreneurs', 'fundamental principles of official statistics', 'social protection policies', 'debt sustainability', 'environmental degradation', 'good governance', 'inclusive', 'environmental policy', 'sustainable public transport', 'international population and housing census', 'sustainability', 'policy coherence', 'wellbeing', 'science cooperation agreements', 'disability', 'smart cities', 'poverty eradication', 'fostering innovation', 'governance and policy', 'international support', 'land locked developing countries', 'pollution air', 'sustainable transport', 'doha development agenda', 'waterenergyfood nexus', 'low impact farming', 'low impact horticulture', 'publicprivate partnerships', 'governance', 'knowledge sharing', 'transboundary cooperation', 'weighted tariff average', 'developing countries', 'human wellbeing', 'forced displacement', 'sustainable societies', 'civil society partnerships', 'co2 emissions', 'technology for sustainable development', 'communication technologies', 'human rights', 'promotion of shared responsibilities', 'technology cooperation agreements', 'capacity building', 'foodenergywater nexus', 'migration and policy', 'low impact agriculture', 'smart houses', 'international aid', 'leave no one behind', 'sustainable development goals', 'global stability', 'sustainable development indicators', 'caring for country', 'ethical', 'foreign direct investments', 'global partnership', 'international cooperation', 'accountability', 'environment', 'small island developing states', 'indigenous knowledge', 'eco tourism', 'global partnership for sustainable development', 'sustainable management', 'international support for developing countries', 'renewable', 'refugee crisis', 'environmentally sound technologies', 'resilient', 'alternative energy', 'governance and risk', 'biodiversity', 'world trade organization', 'ecology', 'water sensitive revitalisation', 'kaitiakitanga', 'technology transfer', 'development assistance', 'multistakeholder partnerships', 'recycling', 'migrant rights', 'environmental', 'teleworking', 'equal rights to economic resources', 'environmental sustainability', 'irregular migration', 'entrepreneurship', 'energy efficiency', 'refugee rights', 'water', 'disaggregated data', 'reuse technologies']\n",
      "\n",
      "Todas las palabras clave expandidas están presentes en la lista original.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sgsr_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sgsr_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "\n",
    "# Descargar recursos de NLTK (si no se han descargado previamente)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def obtener_sinonimos(palabra):\n",
    "    \"\"\"\n",
    "    Obtiene sinónimos de una palabra en inglés utilizando WordNet.\n",
    "    \"\"\"\n",
    "    sinonimos = set()\n",
    "    for syn in wn.synsets(palabra, lang='eng'):\n",
    "        for lemma in syn.lemmas('eng'):\n",
    "            # Reemplazar guiones bajos con espacios y normalizar\n",
    "            sinonimos.add(normalizar_texto(lemma.name().replace('_', ' ')))\n",
    "    return list(sinonimos)\n",
    "\n",
    "# Función para obtener sinónimos restringidos a palabras_clave_normalizadas\n",
    "def obtener_sinonimos(palabra):\n",
    "    \"\"\"\n",
    "    Obtiene sinónimos de una palabra en inglés utilizando WordNet.\n",
    "    Solo devuelve sinónimos que ya están en palabras_clave_normalizadas.\n",
    "    \"\"\"\n",
    "    sinonimos = set()\n",
    "    for syn in wn.synsets(palabra, lang='eng'):\n",
    "        for lemma in syn.lemmas('eng'):\n",
    "            # Reemplazar guiones bajos con espacios y normalizar\n",
    "            sin = normalizar_texto(lemma.name().replace('_', ' '))\n",
    "            if sin in palabras_clave_normalizadas:\n",
    "                sinonimos.add(sin)\n",
    "    return list(sinonimos)\n",
    "\n",
    "# Expansión de palabras clave restringida a palabras_clave_normalizadas\n",
    "palabras_clave_expandidas = set(palabras_clave_normalizadas)\n",
    "for palabra in palabras_clave_normalizadas:\n",
    "    sinonimos_filtrados = obtener_sinonimos(palabra)\n",
    "    palabras_clave_expandidas.update(sinonimos_filtrados)\n",
    "\n",
    "palabras_clave_expandidas = list(palabras_clave_expandidas)\n",
    "\n",
    "print(\"\\nPalabras clave expandidad con sinónimos restringidos:\")\n",
    "print(palabras_clave_expandidas)\n",
    "\n",
    "# Verificar que todas las palabras clave expandidas estén en palabras_clave_normalizadas\n",
    "palabras_no_presentes = [p for p in palabras_clave_expandidas if p not in palabras_clave_normalizadas]\n",
    "if palabras_no_presentes:\n",
    "    print(\"\\nLas siguientes palabras no están en la lista original de palabras_clave:\")\n",
    "    print(palabras_no_presentes)\n",
    "else:\n",
    "    print(\"\\nTodas las palabras clave expandidas están presentes en la lista original.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de conceptos únicos: 139\n",
      "Total de palabras clave expandidas: 101\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo de embeddings multilingüe\n",
    "modelo = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # Puedes elegir otro modelo si lo prefieres\n",
    "\n",
    "# Generar embeddings para palabras clave expandidas\n",
    "embeddings_palabras = modelo.encode(palabras_clave_expandidas, convert_to_tensor=True)\n",
    "\n",
    "# Generar embeddings para conceptos únicos\n",
    "# Primero, aplanamos la lista de conceptos\n",
    "conceptos_unicos = list(set(concepto for conceptos in targets_conceptos for concepto in conceptos))\n",
    "embeddings_conceptos = modelo.encode(conceptos_unicos, convert_to_tensor=True)\n",
    "\n",
    "print(f\"\\nTotal de conceptos únicos: {len(conceptos_unicos)}\")\n",
    "print(f\"Total de palabras clave expandidas: {len(palabras_clave_expandidas)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de mapeo de concepto a palabras clave:\n",
      "- all the sustainable development goals: ['sustainable development', 'technology for sustainable development', 'sustainable development goals', 'sustainable development indicators', 'global partnership for sustainable development']\n",
      "- least developed countries: ['least developed countries']\n",
      "- sustainable development: ['sustainable', 'sustainable development', 'sustainability', 'sustainable societies', 'technology for sustainable development', 'sustainable development goals', 'sustainable development indicators', 'global partnership for sustainable development', 'sustainable management', 'environmental sustainability']\n",
      "- least developed countries share: ['least developed countries']\n",
      "- communications technology: ['communication technologies']\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la matriz de similitud\n",
    "similitudes = util.pytorch_cos_sim(embeddings_conceptos, embeddings_palabras)\n",
    "\n",
    "# Definir umbral de similitud\n",
    "umbral_similitud = 0.7\n",
    "\n",
    "# Crear un diccionario para mapear conceptos a palabras clave\n",
    "mapa_concepto_palabra = {}\n",
    "\n",
    "for idx, concepto in enumerate(conceptos_unicos):\n",
    "    similitudes_concepto = similitudes[idx]\n",
    "    indices_similares = torch.where(similitudes_concepto >= umbral_similitud)[0]\n",
    "    palabras_similares = [palabras_clave_expandidas[i] for i in indices_similares]\n",
    "    if palabras_similares:\n",
    "        mapa_concepto_palabra[concepto] = palabras_similares\n",
    "\n",
    "print(\"\\nEjemplo de mapeo de concepto a palabras clave:\")\n",
    "for concepto, palabras in list(mapa_concepto_palabra.items())[:5]:\n",
    "    print(f\"- {concepto}: {palabras}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clusters de palabras clave similares:\n",
      "Cluster 5: ['sustainable', 'sustainable development', 'sustainability', 'sustainable societies', 'technology for sustainable development', 'sustainable development goals', 'sustainable development indicators', 'sustainable management', 'environmental sustainability']\n",
      "Cluster 10: ['good governance', 'governance and policy', 'governance', 'governance and risk']\n",
      "Cluster 9: ['environmental policy', 'environmental']\n",
      "Cluster 21: ['sustainable public transport', 'sustainable transport']\n",
      "Cluster 14: ['wellbeing', 'human wellbeing']\n",
      "Cluster 8: ['science cooperation agreements', 'technology cooperation agreements']\n",
      "Cluster 12: ['international support', 'international support for developing countries']\n",
      "Cluster 3: ['waterenergyfood nexus', 'foodenergywater nexus']\n",
      "Cluster 7: ['low impact farming', 'low impact agriculture']\n",
      "Cluster 4: ['publicprivate partnerships', 'multistakeholder partnerships']\n",
      "Cluster 6: ['migration and policy', 'irregular migration']\n",
      "Cluster 1: ['global partnership', 'international cooperation', 'global partnership for sustainable development']\n",
      "Cluster 0: ['refugee crisis', 'migrant rights', 'refugee rights']\n",
      "Cluster 2: ['alternative energy', 'energy efficiency']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Extraer los embeddings de las palabras clave\n",
    "embeddings_palabras_np = embeddings_palabras.cpu().numpy()\n",
    "\n",
    "# Aplicar Agglomerative Clustering con el métrico 'cosine'\n",
    "# Nota: 'cosine' métrico se utiliza directamente, no 'precomputed'\n",
    "# linkage='average' es compatible con 'cosine' métrico\n",
    "cluster = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    distance_threshold=0.3,  # Ajusta este umbral según tus necesidades\n",
    "    linkage='average',\n",
    "    metric='cosine'\n",
    "    #metric=None\n",
    ")\n",
    "\n",
    "clusters = cluster.fit_predict(embeddings_palabras_np)\n",
    "\n",
    "# Agrupar palabras clave por clusters\n",
    "from collections import defaultdict\n",
    "\n",
    "clusters_dict = defaultdict(list)\n",
    "for palabra, c in zip(palabras_clave_expandidas, clusters):\n",
    "    clusters_dict[c].append(palabra)\n",
    "\n",
    "print(\"\\nClusters de palabras clave similares:\")\n",
    "for c, palabras in clusters_dict.items():\n",
    "    if len(palabras) > 1:\n",
    "        print(f\"Cluster {c}: {palabras}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras clave representativas por cluster:\n",
      "Cluster 63: soil\n",
      "Cluster 59: free trade\n",
      "Cluster 67: social responsibility\n",
      "Cluster 5: sustainable development\n",
      "Cluster 57: intergenerational\n",
      "Cluster 73: least developed countries\n",
      "Cluster 58: smart grid\n",
      "Cluster 71: women entrepreneurs\n",
      "Cluster 47: fundamental principles of official statistics\n",
      "Cluster 28: social protection policies\n",
      "Cluster 75: debt sustainability\n",
      "Cluster 72: environmental degradation\n",
      "Cluster 10: governance\n",
      "Cluster 49: inclusive\n",
      "Cluster 9: environmental policy\n",
      "Cluster 21: sustainable public transport\n",
      "Cluster 68: international population and housing census\n",
      "Cluster 45: policy coherence\n",
      "Cluster 14: wellbeing\n",
      "Cluster 8: science cooperation agreements\n",
      "Cluster 55: disability\n",
      "Cluster 69: smart cities\n",
      "Cluster 53: poverty eradication\n",
      "Cluster 43: fostering innovation\n",
      "Cluster 12: international support\n",
      "Cluster 46: land locked developing countries\n",
      "Cluster 50: pollution air\n",
      "Cluster 41: doha development agenda\n",
      "Cluster 3: waterenergyfood nexus\n",
      "Cluster 7: low impact farming\n",
      "Cluster 33: low impact horticulture\n",
      "Cluster 4: publicprivate partnerships\n",
      "Cluster 62: knowledge sharing\n",
      "Cluster 51: transboundary cooperation\n",
      "Cluster 56: weighted tariff average\n",
      "Cluster 66: developing countries\n",
      "Cluster 22: forced displacement\n",
      "Cluster 65: civil society partnerships\n",
      "Cluster 60: co2 emissions\n",
      "Cluster 64: communication technologies\n",
      "Cluster 61: human rights\n",
      "Cluster 52: promotion of shared responsibilities\n",
      "Cluster 42: capacity building\n",
      "Cluster 6: migration and policy\n",
      "Cluster 32: smart houses\n",
      "Cluster 74: international aid\n",
      "Cluster 39: leave no one behind\n",
      "Cluster 48: global stability\n",
      "Cluster 20: caring for country\n",
      "Cluster 24: ethical\n",
      "Cluster 38: foreign direct investments\n",
      "Cluster 1: global partnership\n",
      "Cluster 23: accountability\n",
      "Cluster 31: environment\n",
      "Cluster 54: small island developing states\n",
      "Cluster 36: indigenous knowledge\n",
      "Cluster 35: eco tourism\n",
      "Cluster 27: renewable\n",
      "Cluster 0: refugee rights\n",
      "Cluster 30: environmentally sound technologies\n",
      "Cluster 37: resilient\n",
      "Cluster 2: alternative energy\n",
      "Cluster 18: biodiversity\n",
      "Cluster 40: world trade organization\n",
      "Cluster 70: ecology\n",
      "Cluster 34: water sensitive revitalisation\n",
      "Cluster 16: kaitiakitanga\n",
      "Cluster 26: technology transfer\n",
      "Cluster 11: development assistance\n",
      "Cluster 29: recycling\n",
      "Cluster 44: teleworking\n",
      "Cluster 19: equal rights to economic resources\n",
      "Cluster 15: entrepreneurship\n",
      "Cluster 17: water\n",
      "Cluster 25: disaggregated data\n",
      "Cluster 13: reuse technologies\n"
     ]
    }
   ],
   "source": [
    "# Selección de representantes asegurando que pertenezcan a palabras_clave_normalizadas\n",
    "cluster_representante = {}\n",
    "for c, palabras in clusters_dict.items():\n",
    "    if len(palabras) == 1:\n",
    "        palabra = palabras[0]\n",
    "        if palabra in palabras_clave_normalizadas:\n",
    "            cluster_representante[c] = palabra\n",
    "        else:\n",
    "            # Opcional: no asignar representante o asignar una palabra válida\n",
    "            print(f\"Cluster {c} contiene una palabra no deseada: {palabra}. No se asigna representante.\")\n",
    "    else:\n",
    "        # Calcular similitud promedio de cada palabra con las demás en el cluster\n",
    "        indices = [palabras_clave_expandidas.index(p) for p in palabras]\n",
    "        similitudes_cluster = cosine_similarity(embeddings_palabras_np[indices])\n",
    "        sim_promedio = similitudes_cluster.mean(axis=1)\n",
    "        # Seleccionar la palabra con mayor similitud promedio\n",
    "        representante_idx = np.argmax(sim_promedio)\n",
    "        representante = palabras[representante_idx]\n",
    "        if representante in palabras_clave_normalizadas:\n",
    "            cluster_representante[c] = representante\n",
    "        else:\n",
    "            # Elegir la primera palabra que esté en palabras_clave_normalizadas\n",
    "            representante_alternativo = next((p for p in palabras if p in palabras_clave_normalizadas), None)\n",
    "            if representante_alternativo:\n",
    "                cluster_representante[c] = representante_alternativo\n",
    "            else:\n",
    "                print(f\"Cluster {c} no tiene representantes válidos en palabras_clave_normalizadas.\")\n",
    "\n",
    "print(\"\\nPalabras clave representativas por cluster:\")\n",
    "for c, rep in cluster_representante.items():\n",
    "    print(f\"Cluster {c}: {rep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de mapeo de concepto a palabras clave representativas:\n",
      "- all the sustainable development goals: ['global partnership', 'sustainable development']\n",
      "- least developed countries: ['least developed countries']\n",
      "- sustainable development: ['global partnership', 'sustainable development']\n",
      "- least developed countries share: ['least developed countries']\n",
      "- communications technology: ['communication technologies']\n"
     ]
    }
   ],
   "source": [
    "# Mapeo de conceptos a palabras clave representativas\n",
    "mapa_concepto_palabra_representante = {}\n",
    "for concepto, palabras in mapa_concepto_palabra.items():\n",
    "    representantes = set()\n",
    "    for palabra in palabras:\n",
    "        # Encontrar el cluster de la palabra\n",
    "        cluster_id = next((c for c, p in clusters_dict.items() if palabra in p), None)\n",
    "        if cluster_id is not None:\n",
    "            representante = cluster_representante.get(cluster_id, None)\n",
    "            if representante and representante in palabras_clave_normalizadas:\n",
    "                representantes.add(representante)\n",
    "    if representantes:\n",
    "        mapa_concepto_palabra_representante[concepto] = list(representantes)\n",
    "\n",
    "print(\"\\nEjemplo de mapeo de concepto a palabras clave representativas:\")\n",
    "for concepto, palabras in list(mapa_concepto_palabra_representante.items())[:5]:\n",
    "    print(f\"- {concepto}: {palabras}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asignando palabras clave a targets: 100%|██████████| 19/19 [00:00<00:00, 18689.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de palabras clave asignadas a un target:\n",
      "goal_id                                                          17\n",
      "target_id                                                      17.1\n",
      "target            Strengthen domestic resource mobilization, inc...\n",
      "palabras_clave    [international support, international aid, dev...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Asignación de palabras clave a cada target\n",
    "palabras_clave_por_target = []\n",
    "for conceptos in tqdm(targets_conceptos, desc=\"Asignando palabras clave a targets\"):\n",
    "    palabras_asignadas = set()\n",
    "    for concepto in conceptos:\n",
    "        palabras = mapa_concepto_palabra_representante.get(concepto, [])\n",
    "        palabras_asignadas.update(palabras)\n",
    "    palabras_clave_por_target.append(list(palabras_asignadas))\n",
    "\n",
    "# Crear el DataFrame con IDs desde SDG_final.csv\n",
    "targets_df = pd.DataFrame({\n",
    "    'goal_id': goal_ids,\n",
    "    'target_id': target_ids,\n",
    "    'target': targets,\n",
    "    'target_normalizado': targets_normalizados,\n",
    "    'conceptos': targets_conceptos,\n",
    "    'palabras_clave': palabras_clave_por_target\n",
    "})\n",
    "\n",
    "# Mostrar un ejemplo\n",
    "print(\"\\nEjemplo de palabras clave asignadas a un target:\")\n",
    "print(targets_df[['goal_id', 'target_id', 'target', 'palabras_clave']].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de targets sin palabras clave asignadas: 0\n",
      "Empty DataFrame\n",
      "Columns: [target, palabras_clave]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Identificar targets sin palabras clave asignadas\n",
    "targets_df['tiene_palabras_clave'] = targets_df['palabras_clave'].apply(lambda x: len(x) > 0)\n",
    "targets_sin_palabras = targets_df[targets_df['tiene_palabras_clave'] == False]\n",
    "\n",
    "print(f\"\\nTotal de targets sin palabras clave asignadas: {len(targets_sin_palabras)}\")\n",
    "print(targets_sin_palabras[['target', 'palabras_clave']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras clave más frecuentes: ['developing countries', 'international support', 'global partnership']\n",
      "\n",
      "Total de targets sin palabras clave asignadas después de la asignación de palabras frecuentes: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Calcular la frecuencia de cada palabra clave\n",
    "contador_palabras = Counter([palabra for sublist in palabras_clave_por_target for palabra in sublist])\n",
    "palabras_frecuentes = [palabra for palabra, _ in contador_palabras.most_common(3)]  # Top 3 palabras clave\n",
    "\n",
    "print(\"\\nPalabras clave más frecuentes:\", palabras_frecuentes)\n",
    "\n",
    "# Asignar las top 3 palabras clave más frecuentes a targets sin palabras clave\n",
    "for i, row in targets_df.iterrows():\n",
    "    if not row['tiene_palabras_clave']:\n",
    "        targets_df.at[i, 'palabras_clave'] = palabras_frecuentes\n",
    "\n",
    "# Verificar nuevamente\n",
    "print(f\"\\nTotal de targets sin palabras clave asignadas después de la asignación de palabras frecuentes: {len(targets_df[targets_df['palabras_clave'].apply(lambda x: len(x) == 0)])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo CSV generado exitosamente: 'targets_con_palabras_clave_agrupadas.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Concatenar las palabras clave separadas por comas\n",
    "targets_df['palabras_clave_concatenadas'] = targets_df['palabras_clave'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Seleccionar las columnas deseadas, incluyendo goal_id y target_id\n",
    "resultado_csv = targets_df[['goal_id', 'target_id', 'target', 'palabras_clave_concatenadas']]\n",
    "\n",
    "# Definir la ruta del archivo CSV final\n",
    "file_path = 'targets_con_palabras_clave_agrupadas.csv'\n",
    "\n",
    "# Verificar si el archivo ya existe\n",
    "file_exists = os.path.isfile(file_path)\n",
    "# Concatenar las palabras clave separadas por comas\n",
    "targets_df['palabras_clave_concatenadas'] = targets_df['palabras_clave'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Seleccionar las columnas deseadas, incluyendo goal_id y target_id\n",
    "resultado_csv = targets_df[['goal_id', 'target_id', 'target', 'palabras_clave_concatenadas']]\n",
    "\n",
    "# Definir la ruta del archivo CSV final\n",
    "file_path = 'targets_con_palabras_clave_agrupadas.csv'\n",
    "\n",
    "# Verificar si el archivo ya existe\n",
    "file_exists = os.path.isfile(file_path)\n",
    "\n",
    "# Si el archivo ya existe, leerlo para evitar duplicados\n",
    "if file_exists:\n",
    "    final_df = pd.read_csv(file_path)\n",
    "    # Filtrar los targets que ya están en el archivo final\n",
    "    nuevos_resultados = resultado_csv[~resultado_csv['target_id'].isin(final_df['target_id'])]\n",
    "else:\n",
    "    nuevos_resultados = resultado_csv\n",
    "\n",
    "# Guardar los nuevos resultados en el archivo CSV usando append si ya existe\n",
    "nuevos_resultados.to_csv(file_path, mode='a', index=False, header=not file_exists)\n",
    "\n",
    "print(f\"\\nArchivo CSV generado exitosamente: '{file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p_mo412a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
