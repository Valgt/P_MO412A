https://api.elsevier.com/content/article/pii/S2405844024007588 doi:10.1016/j.heliyon.2024.e24727 1-s2.0-S2405844024007588 10.1016/j.heliyon.2024.e24727 S2405-8440(24)00758-8 Fake news research trends, linkages to generative artificial intelligence and sustainable development goals  Heliyon Journal fla 24058440 10 3 e24727 e24727 3 e24727 text/plain 2024-02-15 15 February 2024 © 2024 The Author(s). Published by Elsevier Ltd. The Author(s). Published by Elsevier Ltd. Raman, Raghu Kumar Nair, Vinith Nedungadi, Prema Kumar Sahu, Aditya Kowalski, Robin Ramanathan, Sasangan Achuthan, Krishnashree 
                  In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.
                1 true Full false  Author http://creativecommons.org/licenses/by-nc-nd/4.0/ Deep fake Ethics Fake news Generative AI Prominence percentile Sustainable development goal    https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx10.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx13.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx7.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx4.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx11.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx12.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx14.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx15.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr5a.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx16.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr5b.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx17.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx18.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx19.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr4.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr3.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx20.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx21.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx1.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx6.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr2.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx9.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr1.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx8.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx3.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx2.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx5.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx10.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx13.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx7.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx4.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx11.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx12.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx14.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx15.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr5a.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx16.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr5b.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx17.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx18.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx19.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr4.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr3.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx20.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx21.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx1.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx6.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr2.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx9.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr1.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx8.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx3.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx2.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx5.sml?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx10_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx13_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx7_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx4_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx11_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx12_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx14_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx15_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr5a_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx16_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr5b_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx17_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx18_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx19_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr4_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr3_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx20_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx21_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx1_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx6_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr2_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx9_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-gr1_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx8_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx3_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx2_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-fx5_lrg.jpg?httpAccept=%2A%2F%2A https://api.elsevier.com/content/object/eid/1-s2.0-S2405844024007588-am.pdf?httpAccept=%2A%2F%2A  85184246435 2-s2.0-85184246435  serial JL 313379 291210 291682 291690 291711 291735 291767 291777 291786 291795 291802 291806 291828 291838 291845 291848 291861 291871 291875 291876 291884 291889 291919 291929 291934 291938 31 90  Heliyon HELIYON 2024-01-24 2024-01-24 2024-01-29 2024-01-29 2024-06-26T03:57:28 1-s2.0-S2405844024007588 S2405-8440(24)00758-8 S2405844024007588 10.1016/j.heliyon.2024.e24727 S300 S300.1 FULL-TEXT 1-s2.0-S2405844023X00164 2024-06-26T04:11:41.17396Z 0 0 20240215 2024 2024-01-24T02:23:45.260426Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast orcid primabst pubtype ref 2405-8440 24058440  UNLIMITED NONE true 10 10  3 3  Volume 10, Issue 3 350 e24727 e24727 e24727  20240215  15 February 2024 2024-02-15 2024 Research Article  article fla © 2024 The Author(s). Published by Elsevier Ltd. FAKENEWSRESEARCHTRENDSLINKAGESGENERATIVEARTIFICIALINTELLIGENCESUSTAINABLEDEVELOPMENTGOALS RAMAN R 1 Introduction  2 Methods  3 Results and discussion 3.1 Performance analysis 3.1.1 Publications and citations trends  3.1.2 Top institutions  3.1.3 Highly cited journals  3.1.4 Impact of collaboration   3.2 Thematic clusters based on keyword co-occurrences 3.2.1 Cluster 1: disinformation in social media (red)  3.2.2 Cluster 2: techno-scientific research towards the detection of fake news (green)  3.2.3 Cluster 3: COVID-19-induced infodemics (blue)   3.3 Fake news research mapped to SDGs   4 Fake news in the era of generative AI  5 Emerging research topics based on prominence percentile 5.1 Keyphrases of emerging topics   6 Conclusions  Data availability statement  Funding statement  CRediT authorship contribution statement  Acknowledgements  References   GORDON 2012 432 458 A CONTROVERSIESINMEDIAETHICS INFOTAINMENTSENSATIONALISMREALITY  AIMEUR 2023 E  LIM 2023 W  AMARO 2023 I  DEANGELIS 2023 1166120 L  DADKHAH 2023 M DETECTIONFAKEPAPERSINERAARTIFICIALINTELLIGENCE  KOSNIK 2008 193 214 L  LAI 2013 315 330 C  LEDOUX 2012 653 676 J  NOUR 2022 85 94 N  TSFATI 2020 157 173 Y  TANDOC 2019 e12724 E  BAPTISTA 2020 185 J  MARWICK 2018 474 512 A  GUNAWAN 2022 471 496 B  BRYANOV 2021 e0253717 K  SOLERCOSTA 2021 1212 R  HAGG 2018 92 105 E  SIMON 2015 609 619 T  LI 2019 194 Y  WANG 2019 112552 Y  ROCHA 2021 1 10 Y  ALVAREZGALVEZ 2021 603603 J  SUAREZLLEDO 2021 e17187 V  LING 2021 35 55 G  GABARRON 2021 455 E  AKRAM 2022 e202242 M  ACHUTHAN 2023 107566 K  RAMAN 2022 9160 R  RAMAN 2022 9242 9260 R  JAYABALASINGHAM 2019 1 B  DONTHU 2021 285 296 N  DONTHU 2021 285 296 N  SAU 2022 155 K  PATRA 2022 2001 2020 R GLOBALKNOWLEDGEMEMORYCOMMUNICATION BIBLIOMETRICANALYSISFAKENEWSINDEXEDINWEBSCIENCESCOPUS  CHAUDHARI 2021 57 70 D  VANECK 2010 523 538 N  HA 2021 290 315 L  DING 2021 226 232 Y TIMECONFRONTFAKENEWSRUMORSSOCIALMEDIAABIBLIOMETRICSTUDYBASEDVOSVIEWER  POOL 2021 764 768 J  ROBERGE 2022 G ELSEVIER2022SUSTAINABLEDEVELOPMENTGOALSSDGMAPPING  PAUL 2021 O1 O16 J  RENSTROM 2022 J HOWSCIENCEITSELFFUELSACULTUREMISINFORMATION  ARIA 2017 959 975 M  ZUPIC 2015 429 472 I  SILVA 2020 P  HOWELL L  DELVICARIO 2016 554 559 M  FRENDA 2011 20 23 S  ZUBIAGA 2018 32 A  ROSSLER 2019 1 11 A  RUCHANSKY 2017 797 806 N PROCEEDINGS2017ACMCONFERENCEINFORMATIONKNOWLEDGEMANAGEMENT CSIAHYBRIDDEEPMODELFORFAKENEWSDETECTION  LOOMBA 2021 337 348 S  SALLAM 2021 42 M  KATA 2012 3778 3789 A  LARSON 2011 526 535 H  CINELLI 2020 1 10 M  PENNYCOOK 2020 770 780 G  OPENAI  AKHTAR 2023 633 657 P  MONTOROMONTARROSO 2023 1 16 A  WELLNER 2023 30 G  KIM 2021 e0260080 B  SHIN 2023 241 245 D  CECIL 2023 J  GOLDSTEIN 2022 J  2023 AICHATBOTSSPREADINGFAKENEWSCHATGPTGOOGLEBARDPRODUCINGNEWSRELATEDMISINFORMATIONFINDSREPORT  LAIRD J   COHEN 2023 I  MRIDHA 2021 156151 156170 M  HAJLI 2022 1238 1253 N  RAMAN 2023 R  GRUNEBAUM 2023 696 705 A  KLAVANS 2017 1158 1174 R  NAEEM 2020 233 239 S  VOSOUGHI 2018 1146 1151 S  LEWANDOWSKY 2017 353 369 S  SCHEUFELE 2019 7662 7669 D  HE 2019 28206 28226 M  LAZER 2017 D COMBATINGFAKENEWSAGENDAFORRESEARCHACTION  ABUARQOUB 2022 56 86 O   RAMANX2024Xe24727 RAMANX2024Xe24727XR  Full 2024-01-12T14:36:44Z Author  http://creativecommons.org/licenses/by-nc-nd/4.0/  This is an open access article under the CC BY-NC-ND license.  © 2024 The Author(s). Published by Elsevier Ltd.   2024-02-08T03:29:23.514Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp-car We want to express our immense gratitude to our beloved Chancellor, Mata Amritanandamayi Devi (AMMA), for providing the motivation and inspiration for this research work.   item S2405-8440(24)00758-8 S2405844024007588 1-s2.0-S2405844024007588 10.1016/j.heliyon.2024.e24727 313379 2024-06-26T04:11:41.17396Z 2024-02-15 UNLIMITED NONE 1-s2.0-S2405844024007588-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/MAIN/application/pdf/8e421aa368ec5313435af80aa319105f/main.pdf main.pdf pdf true 8153165 MAIN 17 1-s2.0-S2405844024007588-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/PREVIEW/image/png/47bd0155e5728e419c04d5b0c825ed43/main_1.png main_1.png png 47745 849 656 IMAGE-WEB-PDF 1    1-s2.0-S2405844024007588-fx10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx10/DOWNSAMPLED/image/jpeg/8b08f2f07fe192041433dc30ce4d925f/fx10.jpg fx10 fx10.jpg jpg 77773 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx13.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx13/DOWNSAMPLED/image/jpeg/ba80feea9b65803e4f676e0a79d0ec8c/fx13.jpg fx13 fx13.jpg jpg 69823 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx7/DOWNSAMPLED/image/jpeg/c1d9c933229007cce1299073198dbcda/fx7.jpg fx7 fx7.jpg jpg 73174 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx4/DOWNSAMPLED/image/jpeg/18bcb2b4ee186d7ce0a05e777d5e76cc/fx4.jpg fx4 fx4.jpg jpg 78503 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx11/DOWNSAMPLED/image/jpeg/9c7fdc6022a277552350623069c20f88/fx11.jpg fx11 fx11.jpg jpg 72966 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx12/DOWNSAMPLED/image/jpeg/43ec90a5f5ce1b89165b53cc0d49c89a/fx12.jpg fx12 fx12.jpg jpg 69982 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx14.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx14/DOWNSAMPLED/image/jpeg/ea3ca6a91fdff0474fbf833b4e6728c8/fx14.jpg fx14 fx14.jpg jpg 69232 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx15.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx15/DOWNSAMPLED/image/jpeg/46b6fd73637359ff42217b8359d2acd6/fx15.jpg fx15 fx15.jpg jpg 71843 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-gr5a.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr5a/DOWNSAMPLED/image/jpeg/eed8b5672023d6e789c1d01bdcf020b8/gr5a.jpg gr5a gr5a.jpg jpg 249503 457 624 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx16.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx16/DOWNSAMPLED/image/jpeg/e055239678d8d4e633748290bf757553/fx16.jpg fx16 fx16.jpg jpg 72823 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-gr5b.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr5b/DOWNSAMPLED/image/jpeg/44acc71911285248daec5dc1b728951d/gr5b.jpg gr5b gr5b.jpg jpg 232170 477 624 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx17.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx17/DOWNSAMPLED/image/jpeg/ea2f13c3f7632f555afdbd10d7259507/fx17.jpg fx17 fx17.jpg jpg 73717 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx18.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx18/DOWNSAMPLED/image/jpeg/32f263a52eb59cf5cafd2034198119bc/fx18.jpg fx18 fx18.jpg jpg 73333 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx19.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx19/DOWNSAMPLED/image/jpeg/6698a7ef783044c6fc678fb589c1e1cd/fx19.jpg fx19 fx19.jpg jpg 73337 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr4/DOWNSAMPLED/image/jpeg/ee7f1826ed991dc29b86a4b6dc9a0d7d/gr4.jpg gr4 gr4.jpg jpg 169229 408 624 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr3/DOWNSAMPLED/image/jpeg/1c051f28a338bf1909f6a0bffca1c7e0/gr3.jpg gr3 gr3.jpg jpg 137119 383 624 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx20.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx20/DOWNSAMPLED/image/jpeg/85335df1b85c6be0bdf2860f9f561f2f/fx20.jpg fx20 fx20.jpg jpg 73280 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx21.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx21/DOWNSAMPLED/image/jpeg/48601677e111ee78898817a8fb18ca77/fx21.jpg fx21 fx21.jpg jpg 73005 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx1/DOWNSAMPLED/image/jpeg/d9486cdbb1e8cd39fb080bfd808b8210/fx1.jpg fx1 fx1.jpg jpg 73126 34 102 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx6/DOWNSAMPLED/image/jpeg/4d8cc562f18a9aa43c594a9b1375b983/fx6.jpg fx6 fx6.jpg jpg 71423 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr2/DOWNSAMPLED/image/jpeg/26649bd925c3bb88151bd63de9839d55/gr2.jpg gr2 gr2.jpg jpg 100444 272 491 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx9/DOWNSAMPLED/image/jpeg/75a179ef51932f6fa6ca155c38458286/fx9.jpg fx9 fx9.jpg jpg 74707 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr1/DOWNSAMPLED/image/jpeg/b00506bc2adca88e6fbf7cdaec288435/gr1.jpg gr1 gr1.jpg jpg 234260 912 624 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx8/DOWNSAMPLED/image/jpeg/3312e015d8ec822afc63e43b9a59038a/fx8.jpg fx8 fx8.jpg jpg 77536 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx3/DOWNSAMPLED/image/jpeg/4fd41083538edb868325c3afd3e751d6/fx3.jpg fx3 fx3.jpg jpg 74619 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx2/DOWNSAMPLED/image/jpeg/a290b6cb611e83dbd5532ea32a086979/fx2.jpg fx2 fx2.jpg jpg 74194 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx5/DOWNSAMPLED/image/jpeg/f8534bfabbdfa3da010676f2b0f86140/fx5.jpg fx5 fx5.jpg jpg 71135 33 101 IMAGE-DOWNSAMPLED  1-s2.0-S2405844024007588-fx10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx10/THUMBNAIL/image/gif/ae80878c934f81ca22f6e8798a84be49/fx10.sml fx10 fx10.sml sml 83080 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx13.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx13/THUMBNAIL/image/gif/00f01f2f49c14b3b81ffd41092400774/fx13.sml fx13 fx13.sml sml 76442 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx7/THUMBNAIL/image/gif/da0fde186cee7adb14bdc528de455fc7/fx7.sml fx7 fx7.sml sml 82395 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx4/THUMBNAIL/image/gif/801657b6bafdd7c711fe8c156d0be501/fx4.sml fx4 fx4.sml sml 82599 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx11/THUMBNAIL/image/gif/9ffb22757b9cf08f043c59e9aa5a5be4/fx11.sml fx11 fx11.sml sml 81370 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx12/THUMBNAIL/image/gif/4c4b6398a20e6c9ac465baac6f97d648/fx12.sml fx12 fx12.sml sml 76039 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx14.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx14/THUMBNAIL/image/gif/b94e32a58334e7dd9af33bc9aa6c51eb/fx14.sml fx14 fx14.sml sml 73491 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx15.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx15/THUMBNAIL/image/gif/33efc4b28d032676435f18967b8c9039/fx15.sml fx15 fx15.sml sml 77015 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-gr5a.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr5a/THUMBNAIL/image/gif/5bbe7f6fd1e3d34073f771fa0d6f2441/gr5a.sml gr5a gr5a.sml sml 87729 160 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx16.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx16/THUMBNAIL/image/gif/7300e1a7558496dd71a200f679ff3a5b/fx16.sml fx16 fx16.sml sml 80782 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-gr5b.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr5b/THUMBNAIL/image/gif/014159cf8608a32b5385b815d42ff969/gr5b.sml gr5b gr5b.sml sml 85735 164 214 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx17.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx17/THUMBNAIL/image/gif/3f66459d048855bc7c6745a46f04b5d6/fx17.sml fx17 fx17.sml sml 82653 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx18.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx18/THUMBNAIL/image/gif/a5f67817526dc15c66266ad5a651cb9d/fx18.sml fx18 fx18.sml sml 80983 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx19.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx19/THUMBNAIL/image/gif/bee97e22a327df95bca61c8c651e1390/fx19.sml fx19 fx19.sml sml 80937 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr4/THUMBNAIL/image/gif/82a0901c058e754a9d4d35e15ebcaa90/gr4.sml gr4 gr4.sml sml 83683 143 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr3/THUMBNAIL/image/gif/560b79ad4ecc776f45370ef7e254f1a8/gr3.sml gr3 gr3.sml sml 77692 134 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx20.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx20/THUMBNAIL/image/gif/8e15a31c3534d31b866b8d7aa99b7a68/fx20.sml fx20 fx20.sml sml 81033 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx21.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx21/THUMBNAIL/image/gif/d6b239f70b89fbbcaaeadbb391ae17d2/fx21.sml fx21 fx21.sml sml 79668 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx1/THUMBNAIL/image/gif/2e47784c148a87546310c772d6b952c0/fx1.sml fx1 fx1.sml sml 80868 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx6/THUMBNAIL/image/gif/96a3ae67e60dc4fdc965ed113047e5cb/fx6.sml fx6 fx6.sml sml 78200 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr2/THUMBNAIL/image/gif/dab8fc34e60da64861d253802ca72371/gr2.sml gr2 gr2.sml sml 71808 121 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx9/THUMBNAIL/image/gif/13383cd26efed6865b2def6a165b5376/fx9.sml fx9 fx9.sml sml 82611 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/gr1/THUMBNAIL/image/gif/5b370f9f040f97e3d702134437975a90/gr1.sml gr1 gr1.sml sml 78260 164 112 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx8/THUMBNAIL/image/gif/35f2d8d7c620d0d8f3b6a35024c6650d/fx8.sml fx8 fx8.sml sml 80392 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx3/THUMBNAIL/image/gif/bafd3e16a707f791765deb23f34f106c/fx3.sml fx3 fx3.sml sml 84647 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx2/THUMBNAIL/image/gif/fd61d80b620b7bc17be6a6f63abd4a21/fx2.sml fx2 fx2.sml sml 80759 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/fx5/THUMBNAIL/image/gif/569e58f3ec2c170e3f2f8a56b49955cc/fx5.sml fx5 fx5.sml sml 77614 72 219 IMAGE-THUMBNAIL  1-s2.0-S2405844024007588-fx10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/ca87c7761da8f54949c10fc139f3440c/fx10_lrg.jpg fx10 fx10_lrg.jpg jpg 96687 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx13_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/61bb47836f740424605ba86ffa5bf59f/fx13_lrg.jpg fx13 fx13_lrg.jpg jpg 81934 147 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/07fa0dee90174f0c971be214e8319b24/fx7_lrg.jpg fx7 fx7_lrg.jpg jpg 96559 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/dd42788a891b9cdbf2947d988a0ed6fd/fx4_lrg.jpg fx4 fx4_lrg.jpg jpg 97200 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx11_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/14aa9cebf37c274244599ea1a36aa6fb/fx11_lrg.jpg fx11 fx11_lrg.jpg jpg 93914 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx12_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/e3e7df2c49e6add51f5b5c914af689dc/fx12_lrg.jpg fx12 fx12_lrg.jpg jpg 83166 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx14_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/1520bfe566c1b5175044bb0977621682/fx14_lrg.jpg fx14 fx14_lrg.jpg jpg 79629 147 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx15_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/f38aaddb44310e569b9c74ff2c610288/fx15_lrg.jpg fx15 fx15_lrg.jpg jpg 89620 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-gr5a_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/b4029abd8dd1c30b029266c6d07293c2/gr5a_lrg.jpg gr5a gr5a_lrg.jpg jpg 1573808 2025 2764 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx16_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/8cd10efae5d919ba27e11066482884a6/fx16_lrg.jpg fx16 fx16_lrg.jpg jpg 93332 147 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-gr5b_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/bb7a07e389b0b4dfa41923500094b5a0/gr5b_lrg.jpg gr5b gr5b_lrg.jpg jpg 1442141 2115 2764 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx17_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/886d0bac710d677e7a0bc98e24da072a/fx17_lrg.jpg fx17 fx17_lrg.jpg jpg 98568 149 451 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx18_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/6a413a767c8861530068b6b24899d904/fx18_lrg.jpg fx18 fx18_lrg.jpg jpg 94934 149 451 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx19_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/2ef3d7ebc232a5e6ce2ea41954ca3ce1/fx19_lrg.jpg fx19 fx19_lrg.jpg jpg 94821 149 451 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/dc23c38d9971c9749a8953f5c3f64d2e/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 873858 1806 2764 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/4bb24bbafd58ca023abdb01f297f4f7f/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 596493 1695 2764 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx20_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/5642cdaab27ba9b475f931488cad9c2c/fx20_lrg.jpg fx20 fx20_lrg.jpg jpg 94687 149 451 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx21_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/ffe086c8e6d5f9dd388ee4976d3c9362/fx21_lrg.jpg fx21 fx21_lrg.jpg jpg 94390 149 451 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/381d7c1604459dcbe89d6fb62e50aac6/fx1_lrg.jpg fx1 fx1_lrg.jpg jpg 93555 149 453 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/2b838e991a7c84cdb735f7c2476ab338/fx6_lrg.jpg fx6 fx6_lrg.jpg jpg 88736 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/93da386686166c31bb6de3a402e3bb25/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 302512 1203 2174 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/7d66426a03840706d144d7a7398696e3/fx9_lrg.jpg fx9 fx9_lrg.jpg jpg 99324 147 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/3fc76f3f0e234acdbf72c3db7a70a1be/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 1372311 4040 2764 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/eb000fc84edd48902be9136ebdaf3833/fx8_lrg.jpg fx8 fx8_lrg.jpg jpg 93616 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/28b6881fb8ae1ac6547067ee26eee884/fx3_lrg.jpg fx3 fx3_lrg.jpg jpg 101987 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/8ae1800bfdc25afd5c38715625fccd8a/fx2_lrg.jpg fx2 fx2_lrg.jpg jpg 98252 147 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-fx5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844024007588/HIGHRES/image/jpeg/a78644f388462d75c656bd1dbbdedd14/fx5_lrg.jpg fx5 fx5_lrg.jpg jpg 86991 148 450 IMAGE-HIGH-RES  1-s2.0-S2405844024007588-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10TGFJJ6Q54/MAIN/application/pdf/cf129ab9150e6fdf8828e701ad1a0713/am.pdf am am.pdf pdf false 2414921 AAM-PDF     HLY 24727 e24727 S2405-8440(24)00758-8 10.1016/j.heliyon.2024.e24727 The Author(s)  Fig. 1 SPAR-4-SLR protocol-based research design.  Fig. 1   Fig. 2 Publications and Citations trends. Note:  TP = Total publications; TC = Total citations.  Fig. 2   Fig. 3 Bibliographic coupling of journals.  Fig. 3   Fig. 4 Keyword co-occurrence network.  Fig. 4   Fig. 5 Keyphrases for the top prominent topics  Fig. 5    Table 1 Top 10 institutions ranked according to publications and citations.  Table 1           Ranked according to TP Ranked according to TC  Institution Country TP TC TC/TP Institution Country TC TP TC/TP   Harvard University United States 99 4171 42.1 Massachusetts Institute of Technology United States 7168 68 105.4  Nanyang Technological University Singapore 97 2759 28.4 New York University United States 5070 70 72.4  University of Oxford United Kingdom 91 1346 14.8 Stanford University United States 4821 66 73.0  Chinese Academy of Sciences China 81 2345 29.0 Harvard University United States 4171 99 42.1  Arizona State University United States 80 2312 28.9 University of Southern California United States 3995 73 54.7  University of Texas at Austin United States 80 986 12.3 Indiana University Bloomington United States 3238 67 48.3  Pennsylvania State University United States 76 2227 29.3 National Bureau of Economic Research United States 2943 3 981.0  University of Southern California United States 73 3995 54.7 National Research Council of Italy Italy 2909 40 72.7  University of Chinese Academy of Sciences China 71 2151 30.3 University of Washington United States 2883 54 53.4  New York University United States 70 5070 72.4 Nanyang Technological University Singapore 2759 97 28.4    Note:  TP = Total publications; TC = Total citations; TC/TP = Total citations per publication.   Table 2 Top ten journals based on citations.  Table 2      Journal Title TC TP TC/TP SJR   Journal of Medical Internet Research 3500 86 40.7 Q1  PLoS ONE 3444 94 36.6 Q1  Lecture Notes in Computer Science 2584 444 5.8 Q3  Digital Journalism 2334 44 53.0 Q1  Proceedings of the National Academy of Sciences of the United States of America 2317 16 144.8 Q1  IEEE Access 1943 80 24.3 Q1  International Journal of Environmental Research and Public Health 1782 84 21.2 Q1  New Media and Society 1525 50 30.5 Q1  Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 1427 18 79.3 –  JMIR Public Health and Surveillance 1296 24 54.0 Q1    Note : TP = Total publications; TC = Total citations; TC/TP = Total citations per publication; SJR= Scimago Journal Rank.   Table 3 Impact of collaboration.  Table 3     Metric % Share TC TC/TP   International collaboration 19.3 % 48,734 22.0  Only national collaboration 24.2 % 44,753 16.1  Only institutional collaboration 34.3 % 50,883 12.9  Single authorship (no collaboration) 22.2 % 17,387 6.8    Note:  TP = Total publications; TC = Total citations; TC/TP = Total citations per publication.   Table 4 Thematic clusters based on keyword co-occurrence.  Table 4     Cluster Cluster 1 (red) Cluster 2 (green) Cluster 3 (blue)   Cluster theme  Disinformation in social media Techno-scientific research for auto-detection of fake news COVID-19-induced infodemics  TP  3273 4293 3983  TC/TP  15.6 15.6 17.9  TC  51141 66856 71370  Top ten keywords  fake news disinformation twitter media literacy fact checking post-truth journalism facebook political communication trust machine learning deep learning natural language processing deep fake artificial intelligence rumour sentiment analysis text classification neural network support vector machine social media misinformation covid-19 infodemic coronavirus pandemic vaccination internet public health health communication vaccine hesitancy  Top three cited articles, their focus, number of citations  Del Vicario, M.D. et al. Misinformation online TC = 1029 Wang, Y. et al. Health Misinformation on Social Media TC = 589 Zubiaga, A. et al. Rumours in social media TC = 79 Tandoc, E.C. et al. Typology for fake news TC = 981 Rossler, A. et al. Machine learning detection TC = 977 Ruchansky, N. et al. Deep learning for fake news TC = 588 Kata, A. Anti-vaccine TC = 584 Cinelli, M. et al. COVID-10 infodemic TC = 742 Pennycook, G. et al. COVID-19 Misinformation TC = 717    Next, we analyze the top three cited articles from each of the clusters.   Table 5 Total publications on fake news research mapped to SDGs.  Table 5   SDG Name SDG Mapped publications    Image 1   1610   Image 2   857   Image 3   214   Image 4   180   Image 5   159   Image 6   117   Image 7   116   Image 8   86   Image 9   70   Image 10   49   Image 11   40   Image 12   26   Image 13   26   Image 14   25   Image 15   17   Image 16   11     Table 6 Highly cited SDG-mapped publications.  Table 6        Title TC Year TC/Year Authors Journal title SDG Mappings   The spread of true and false news online 3210 2018 642 Vosoughi, S. et al. Science   Image 17    The COVID-19 social media infodemic 742 2020 247 Cinelli, M et al. Scientific Reports   Image 18     717 2020 239 Pennycook, G. et al. Psychological Science   Image 19    Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA 646 2021 323 Loomba, S. et al. Nature Human Behaviour   Image 20    Beyond Misinformation: Understanding and Coping with the “Post-Truth” Era 606 2017 101 Lewandowsky, S. et al. Journal of Applied Research in Memory and Cognition   Image 21       Table 7 Emerging research topics according to Prominence Percentile.  Table 7      Research Topic PP TP TC TC/TA   Object Detection; Deep Learning; IOU 99.999 56 190 3.4  COVID-19; Psychological Support; Mindfulness 99.997 100 1872 18.7  Bitcoin; Ethereum; Internet Of Things 99.990 53 1205 22.7  Vaccine Hesitancy; Measles; Anti-Vaccination Movement 99.971 399 8230 20.6  Embedding; Named Entity Recognition; Entailment 99.949 220 1954 8.9  Rumour; Social Media; Disinformation 99.820 3128 62517 20.0  Intergovernmental Panel on Climate Change; Climate Change; Skepticism 99.735 93 1577 17.0  Political Participation; Social Media; Media Use 99.538 313 6107 19.5    Now, we analyze the top-cited publications from each of the emerging topics (Table 8 ).   Table 8 Top cited publication from each of the topics from Table 7 .  Table 8      Topic No. Topic name Publication title Authors TC   1 Object Detection; Deep Learning; IOU Adversarial Perturbations Fool Deepfake Detectors Gandhi and Jain (2020) 37  2 COVID-19; Psychological Support; Mindfulness The Covid-19 ‘infodemic’: a new front for information professionals (Naeem and Bhatti, 2020) 161  3 Bitcoin; Ethereum; Internet Of Things A Comprehensive Review of the COVID-19 Pandemic and the Role of IoT, Drones, AI, Blockchain, and 5G in Managing its Impact Chamola et al. (2020) 681  4 Vaccine Hesitancy; Measles; Anti-Vaccination Movement Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA Loomba et al. (2021) 644  5 Embedding; Named Entity Recognition; Entailment “Liar, liar pants on fire”: A new benchmark dataset for fake news detection Wang, W.Y. (2020) 497  6 Rumour; Social Media; Disinformation The spread of true and false news online Vosoughi et al. (2018) 3203  7 Intergovernmental Panel on Climate Change; Climate Change; Skepticism NASA Faked the Moon Landing-Therefore, (Climate) Science Is a Hoax: An Anatomy of the Motivated Rejection of Science Lewandowsky et al. (2013) 368  8 Political Participation; Social Media; Media Use Science audiences, misinformation, and fake news Scheufele and Krause (2019) 381      Research article  Fake news research trends, linkages to generative artificial intelligence and sustainable development goals Raghu Raman Writing – review & editing Writing – original draft Conceptualization a  ∗   Vinith Kumar Nair Writing – review & editing Methodology Investigation Data curation a   Prema Nedungadi Writing – review & editing Writing – original draft b   Aditya Kumar Sahu Writing – review & editing Investigation c   Robin Kowalski Writing – review & editing Writing – original draft d   Sasangan Ramanathan Writing – review & editing e   Krishnashree Achuthan Writing – review & editing Writing – original draft Methodology Investigation Conceptualization f   a Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala, 690525, India Amrita School of Business Amrita Vishwa Vidyapeetham Amritapuri Kerala 690525 India  Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala - 690525, India  b Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala, 690525, India Amrita School of Computing Amrita Vishwa Vidyapeetham Amritapuri Kerala 690525 India  Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala - 690525, India  c Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amaravati, Andhra Pradesh, 522503, India Amrita School of Computing Amrita Vishwa Vidyapeetham Amaravati Andhra Pradesh 522503 India  Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amaravati, Andhra Pradesh - 522503, India  d College of Behavioral, Social and Health Sciences, Clemson University, Clemson, SC, 29634, USA College of Behavioral Social and Health Sciences Clemson University Clemson SC 29634 USA  College of Behavioral, Social and Health Sciences, Clemson University, Clemson, SC, 29634, USA  e Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, Tamilnadu, 641112, India Amrita School of Engineering Amrita Vishwa Vidyapeetham Coimbatore Tamilnadu 641112 India  Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, Tamilnadu, 641112, India  f Center for Cybersecurity Systems and Networks, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala, 690525, India Center for Cybersecurity Systems and Networks Amrita Vishwa Vidyapeetham Amritapuri Kerala 690525 India  Center for Cybersecurity Systems and Networks, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala, 690525, India  ∗ Corresponding author.      In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.   Keywords Deep fake  Ethics  Fake news  Generative AI  Prominence percentile  Sustainable development goal    1 Introduction With the proliferation of digital social media platforms and the enablement of instant messaging services, traditional journalism has evolved into integrating sensationalism into the news [1 ]. At the same time, it is never wrong to use literary tactics to attract the reader's attention, convoluting the truth and spreading misinformation. The need to gain popularity and likeability amidst stiff competition has facilitated the tendency of some news and social media providers to overlook ethical aggregation and dissemination of information. Fake news or the dissemination of false information as if it were true [2 ,3 ] has become a deplorable problem since it intentionally manipulates facts to spread misinformation and deceive the audience. Research into fake news within the context of generative AI is crucial, as advanced AI algorithms have increasingly become tools for both generating and detecting deceptive information [4 ,4 ,6 ]. Understanding the capabilities of generative AI in creating convincing fake narratives is vital for crafting more effective countermeasures, as well as for assessing the ethical implications associated with AI-enabled misinformation. The availability of information and its quality have a proportional relationship with decision-making. However, the inherent biases, either implicit or confirmatory, cloud the knowledge gained, impairing objective decision-making [7 ,8 ]. Prior studies have shown how personal experiences from physical interactions embed information that leads one to develop a positive, negative, or neutral outlook on current circumstances. More recent studies [9 ] indicate that different circuits within the brain are attributable to ingraining positive or negative experiences and the decision to rely on them. Thus, the resources that provide information directly impact our opinions, reactions, and behaviour. Humans also tend to gravitate towards sensational and negative news or information, irrespective of their relevance. Fake news encapsulates both misinformation and disinformation [2 ,10 ], the latter two differing from one another along continuums of truth and intent. Disinformation reflects the spread of untrue information known to be false by the person disseminating the information [3 ], thereby reflecting falsehood and malicious intent. Misinformation refers to the spread of false information perceived to be true by the sender, thereby reflecting falsehood and non-malicious intent. The recent past has seen significant growth in fake news with surprisingly significant contributions from mainstream media, as Tsfati et al. [11 ] reported. Their review paper succinctly presents worldwide examples of the wide-ranging impact of fake news, especially with political agenda at the core of disinformation campaigning strategy and even swaying election results in developed countries. This weaponizing tendency of fake news with financial and ideological allegiances was further elaborated by Tandoc Jr [12 ]. in his review. Study by Baptisda et al. [13 ] detail the linguistic characteristics and motivations that aid in sharing and consuming fake news. This finding requires delving into both ends of the spectrum, i.e., specific elements of the shared content and demographics of those engulfed by fake news. Their work exposes the underlying causes for creating and disseminating the fakest news induced by social reputation reinforcement and justification of beliefs that may be deep, partisan, polarized or ideological [14 ]. The persuasive language and graphics are intended to invoke provocation and go viral. Perhaps the only way to mitigate the impact of fake news is to create awareness among those most vulnerable [15 ]. A complimentary review by Bryanov et al. [16 ] elaborates on the compelling traits of people most susceptible to fake news. The tendency to dwell on or believe fake news depended on consumers’ naiveté, emotionality, and lack of analytical or reflective thinking. Other factors, such as  frivolous time spent online or on social media, also heightened their propensity. The question remains: what type of systemic changes can transform this draw toward fake news? Soler-Costa et al. [17 ] refer to the dire need for promoting ‘netiquette', a burgeoning field of research combining ethics, education, and behaviour on the internet. Social media has been a powerful tool during emergencies [18 ,19 ] for getting swift public involvement in rescue operations and online support. Due to a lack of awareness of verifiability, the risk of misinformation is rampant in such situations. Before the pandemic, the research on health misinformation [20 ,21 ], portrayed disinformation primarily related to vaccines and infectious diseases. However, there was a lack of sufficient data and theory-driven methods to draw adequate conclusions on user susceptibility. COVID-19 flooded social media with information, and the tremendous anxiety and panic augmented the spread of related news with little or no self-regulation of facts [22 ]. The coining of new terminology 'infodemics' during the pandemic [23 ] is a testament to the aggressive discordant dimension of fake news. Suarez-Lledo et al. [24 ] developed methodologies to measure the spread of health misinformation and found Twitter to be the most exploited platform, which was further confirmed by Ling et al. [25 ]. Fake news had up to 87 % spread in some cases. Gabarron et al. [26 ] comprehensively reviewed 22 studies on the COVID pandemic that highlighted tackling strategies such as demystifying hoaxes, health literacy and improved social media regulatory policies. While these futuristic suggestions are helpful, their implementation in developing or populous countries with many illiterate and vulnerable citizens can be challenging. Akram et al. [27 ] portray a noticeable gap in comprehending the direct impact of disinformation on the construction of communal psychosocial narratives. With the deadline for the Sustainable Development Goals (SDGs) set for 2030 rapidly drawing near, the urgency to meet these objectives is mounting, stimulating intensified research activity in various fields. The SDGs were articulated with a vision to empower people, communities and nations with economic prosperity and healthy living and to protect the environment using balanced approaches. Fake news that compromises the integrity of organizations, personalities or countries can directly impact their economic stature and public trust. Several sustainable development goals, such as SDGs 4 (Quality Education), 10 (Reduced Inequalities), 13 (Climate Action), and 16 (Peace, Justice, and Institutions), will remain unachievable due to the debilitating impact of fake news. The issue of misinformation is complex in that it is prevalent even among trained scientific personnel. For example, publications that lack sufficient rigour render them non-reproducible and potentially unreliable. When others cite such studies, the domino effect of misinformation continues [6 ]. SDG 4 targets the provision of equal opportunity in education to all. When even well-educated professionals are susceptible to fake news such as the scientific community, it is unsurprising that the dynamics and purposes of misinformation will be much less evident to the larger masses. When it comes to scientific phenomena that have a long-term impact, such as SDG 13, challenges exist with verifiability that can lead to the exposition and spread of misleading information. The costs to disprove falsity are also staggering and unrealistic. Despite numerous studies aiming to map research domains with the SDGs [28–30 ], there exists a conspicuous lack of systematic study of fake news-related research mapped to individual SDGs. Our study seeks to fill this void, leveraging the Elsevier SDG Mapping Initiative to introduce a fresh viewpoint on this topic [31 ]. Our research aims to address the following questions.1. What are the evaluation patterns of fake news research, as measured by the temporal growth in publications and citations, contributions from top institutions, highly cited journals, and the impact of collaboration?  2. What are the thematic clusters based on keyword co-occurrence analysis?  3. How well does fake news research map to Sustainable Development Goals?  4. What is the role of generative AI in the propagation of fake news?  5. Which are the emerging topics related to fake news research based on prominence percentile?    The study starts by describing the protocol used for the systematic literature review, followed by the results and discussion sections. The overall research performance and temporal evolution of publications and citations, patterns of top institutions and highly cited journals, and the impact of collaboration are highlighted in the discussion section. The next section describes the thematic structure of fake news research based on keywords. This is followed by a section describing the mapping of fake news research to SDGs. In the following section, we discuss fake news research in the context of generative AI, which is a first. Then, we discuss implications for future research based on prominence topics and keyphrases, which is a unique contribution of our study. The conclusions and limitations of the study are discussed in the last section.  2 Methods The field of bibliometrics studies publication and citation patterns by using quantitative techniques. Bibliometrics can be either descriptive, i.e., analyzing the publications by an organization, or evaluative, i.e., exploring how the publications influenced subsequent research by others using various techniques like citation analysis. Performance analysis uses publications and citation data to assess multiple scientific characteristics, including countries, institutions, etc. and science mapping analysis, which evaluates the social and cognitive makeup of a study area [32 ,33 ]. The top-cited fake news publications and the journals that most frequently cite those publications were identified for analyzing the recognition and influence of fake news publications. The Scopus database was chosen as it has strict quality standards for indexation, and the journals it indexes are more comprehensive [34 ]. Scopus is the most important citation and abstract database and the most widely used search database [35 ]. The Science mapping technique that uses the thematic development of the study topic's co-occurrence analysis was used as part of the study (Chen et al., 2017). In the study, to investigate the evolution of themes about fake news, authors and index keywords were retrieved and thematically organized into groups [16 ,36 ]. VOSviewer and Scival are used for bibliometric analysis and network visualizations [29 ]. VOSviewer creates and displays bibliometric maps [37 ], demonstrating science investigation's dynamic and structural features [38 ]. This software is used for keyword co-occurrence analyses and bibliographic coupling. Bibliographic coupling [39 ,40 ] is used in the study, which occurs when two documents cite the same third document. This technique is used to understand patterns of intellectual content shared between the publications. The Elsevier SDG Mapping Initiative [41 ], a feature integrated within the Scopus database, utilizes distinct SDG-specific queries created in line with the targets and sub-targets of each goal. This tool has been refined through an extensive process of review and feedback, complemented by a machine learning model to ensure a precision rate above 80 %. Furthermore, the Scopus database enhances the research procedure by offering preset search queries for each SDG. Preparing a protocol is the first step in the systematic literature review. A protocol ensures careful planning, consistency in implementation, and transparency, enabling replication. SPAR-4-SLR protocol developed by Paul et al. [42 ] has been used in this study, as highlighted in Fig. 1  . This protocol consists of three main steps – Assembling (identification and acquisition), Arranging (organization and purification), and Assessing (evaluation and reporting). Data identification happened between the 1st and May 6, 2023.  3 Results and discussion 3.1 Performance analysis 3.1.1 Publications and citations trends Fig. 2   shows the publication and citation trends of articles per year related to fake news research. As we have frequently seen over the past two years, COVID-19 has been not only a viral pandemic but also a pandemic of false information. The World Health Organization defines it as an “infodemic" [43 ]. Fake news attracted the attention of academics due to the increasing attention given to the COVID-19 pandemic between 2020 and 2022. The dominant number of publications were made during 2022. Almost 77 % of the entire publication count during 2013–2022 was in 2020, 2021 and 2022, which possibly shows higher influence of social media and COVID-19. About 31 % of publications were related to Fake news and COVID-19.  3.1.2 Top institutions It is essential to recognize the top contributing institutions researching fake news-related topics. Table 1   shows the top institutions, publications (TP), citation (TC), and citation mean (TC/TP) ranked by citations. The outcomes portray that 80 % of the top 10 institutions belong to the United States. Massachusetts Institute of Technology (MIT) in the US has the highest citation count (TC:4171). Still, when looking into the citation mean ratio, the National Bureau of Economic Research (NBER) has the highest TC/TP:981. The top four institutions that lead in terms of TC are from the United States, i.e., MIT, New York University, Stanford University and Harvard University. They have TCs of 7168, 5070, 4821 and 4171, respectively. Italy and Australia are the only two non-US countries with universities on this list.  3.1.3 Highly cited journals Between 2013 and 2022, the distribution of publications and citations among the journals that contribute the most to fake news was analyzed. Table 2   shows the top ten journals publishing fake news, with metrics aimed at assessing their impact and quality. The “Journal of Medical Internet Research" and “PLoS ONE" stand out with exceptionally high TC values of 3500 and 3444, respectively, along with Q1 SJR rankings. These metrics signify not only the prolific citation of their articles but also their top-tier quality within their subject areas. In contrast, “Lecture Notes in Computer Science" has a lower TC/TP ratio of 5.8 and a Q3 SJR rank, which may suggest a narrower impact or specialized focus. Furthermore, “Proceedings of the National Academy of Sciences of the United States of America" exhibits an extraordinarily high TC/TP ratio of 144.8, underscoring the high-impact nature of its publications despite a low TP of 16. Bibliographic coupling occurs when two documents cite a common third document and is frequently used as a measure of similarity among documents [44 ,45 ]. The network map shown in Fig. 3   demonstrates that two main clusters of publication sources cite each other. It also means that the links between documents will remain constant over time [46 ]. A threshold of 20 publications was kept, identifying the bibliographic coupling of sources, and 37 publication sources met the threshold. Cluster 1 (Red) has 24 journals, and Cluster 2 (Green) has 13 publication sources. The publication source with the most publications and citations in Cluster 1 is the Journal of Medical Internet Research  (TP:86, TC:2909), and in Cluster 2 is Lecture Notes in Computer Science  (TP:277, TC:1812). The first cluster has the Proceedings of the ACM on Human-Computer Interaction  (LS:12005) with the highest link strength and is mainly sharing links with New Media and Society  (LS:11756) and Digital Journalism  (LS:10847). The second cluster has Lecture Notes in Computer Science  with the highest link strength. It is mainly coupled with CEUR Workshop Proceedings  (LS:28091), ACM International Conference Proceeding Series  (LS:21534), and IEEE Access  (LS:14352).  3.1.4 Impact of collaboration The extent to which an entity's publications have international, national, or institutional co-authorship and single authorship indicates collaboration. Table 3   displays the collaboration pattern over the years 2013–2022. Notably, international collaboration yields the highest TC/TP ratio of 22.0 despite accounting for only 19.3 % of the total publications share. This suggests that publications arising from international collaborations are generally more cited and potentially have a broader impact. Publications resulting from only national collaboration represent 24.2 % of the share and have a lower TC/TP ratio of 16.1, indicating a comparatively reduced but still significant impact. Publications originating from institutional collaborations occupy the largest share at 34.3 %, yet they have a lower TC/TP ratio of 12.9, suggesting that such collaborations, while more frequent, do not necessarily lead to higher-impact papers. Finally, single-author papers, with no collaboration, account for 22.2 % of the total share but have the lowest TC/TP ratio of 6.8, which may indicate a more limited scope or impact.   3.2 Thematic clusters based on keyword co-occurrences Keyword co-occurrence analysis reveals the structure of a research landscape by identifying relationships between keywords. Node size signifies keyword frequency and importance, colour distinguishes thematic clusters, and edge thickness indicates the strength of keyword associations. The keyword co-occurrence network has resulted in three thematic clusters, as seen in Fig. 4  . Table 4   has further details about each cluster. 3.2.1 Cluster 1: disinformation in social media (red) Cluster 1 is focused on disinformation in news, journalism, social media, Twitter, Facebook, political conspiracy theory, propaganda, digital media and bots. The cluster also includes media literacy, fact-checking, information literacy, credibility, and truth to counter disinformation. With the proliferation of social media platforms and the enablement of instant messaging services, traditional journalism has evolved into integrating sensationalism into the news. The recent past has seen considerable growth in fake news with surprisingly significant contributions from mainstream media, as reported by Ref. [11 ]. The first article in this cluster by Del Vicario, MD et al. states that misinformation online, including fake news, has become a major issue on social media platforms and is recognized as a threat to society by the World Economic Forum [47 ]. Once accepted, it can be difficult for individuals to correct false information. Social norms and personal beliefs can influence the acceptance of news items [48 ,49 ]. The next research emphasizes that health misinformation on social media often revolves around themes such as vaccines, infectious diseases, cancer, smoking, and nutrition [21 ]. The spread, impact, and strategies for coping with this type of misinformation on social media are also important areas of study. The open nature of social media platforms provides opportunities for researchers to study how users share and discuss rumours and to develop techniques for automatically assessing their veracity, such as natural language processing and data mining. Researchers of the last article classify rumours such as rumour detection, rumour tracking, rumour stance classification, and rumour veracity classification [50 ]. These approaches can help to understand better the nature and impact of rumours on social media.  3.2.2 Cluster 2: techno-scientific research towards the detection of fake news (green) Articles included in Cluster 2 often involve the use of machine learning, artificial intelligence, deep learning, and natural language processing techniques. These techniques can be used to automate the process of classifying news as fake or real. Deepfake, in particular, uses deep learning techniques to generate realistic images and videos, which has led to an increase in research on techniques for detecting deepfake images and videos. Textual fake news techniques often utilize embedding and named entity recognition, along with textual entailment, to determine the logical flow of the text. The proliferation of fake news on social media and other online platforms, often spread through clickbait and online social networks, has made the development of these detection techniques increasingly important. Fake news can be classified into several categories based on levels of deception and facticity: (1) news satire, (2) news parody, (3) fabrication, (4) manipulation, (5) advertising, and (6) propaganda (Tandoc et al., 2017). In addition to these categories, fake news can also be spread with news bots, which create a network of fake sites that imitate the omnipresence of news [2 ]. The next article looks at the ease of manipulation and generation of images, which has led to the development of deep learning methods for detecting synthetic or modified images, including facial images and poor-quality video [51 ]. These approaches can help to counter the spread of fake news and disinformation on social media and other online platforms. Fake news can be characterized by three factors: the content of the article, the user response it receives, and the sources promoting it. The last article in this cluster proposes a model called Capture, Score, and Integrate (CSI) that combines all three characteristics to improve the accuracy and automation of fake news detection, outperforms existing models and extracts meaningful latent representations of both users and articles [52 ].  3.2.3 Cluster 3: COVID-19-induced infodemics (blue) COVID-19 has led to an increase in the spread of misinformation, also known as an “infodemic," on social media. This flood of information, combined with anxiety and panic about the virus, has led to the rapid spread of false or misleading news with little fact-checking. This has caused panic, mental distress, and vaccine hesitancy in countries around the world, including the US and the UK [22 ,53 ,54 ]. The term “infodemic" has been coined to describe the aggressive and discordant nature of fake news related to the pandemic [23 ]. Individuals need to be vigilant and critically evaluate the sources and accuracy of information they encounter about COVID-19, especially given the potential impact on public health and vaccine uptake. In the current healthcare landscape, there has been a shift in power from doctors to patients, and there is a growing trend of questioning the legitimacy of science and redefining expertise. This has created an environment in which anti-vaccine activists are able to spread their messages effectively [55 ]. Research has shown that individuals often turn to the internet for vaccination advice and these sources can influence vaccination decisions [56 ]. In the next article, researchers conducted data analysis on multiple social media platforms to study the diffusion of information about COVID-19 (Cinelli et al. n. d.). They analyze engagement and interest in the topic with epidemic models and identify the spread of misinformation from questionable sources [57 ]. The last article in this cluster looks at cognitive factors, such as a lack of critical thinking, that contribute to the sharing of misinformation online. Simple interventions, like reminding people to fact-check before sharing, can help reduce the spread of false information [58 ].   3.3 Fake news research mapped to SDGs The study of fake news and its relationship to Sustainable Development Goals (SDGs) is highly relevant for researchers for several reasons. Table 5   shows the total articles on fake news research sorted according to SDGs. Only 27 % of the corpus is found to be mapped to SDGs using the SDG mapping algorithm [31 ]. The greatest number of articles (TP:1610) is in SDG 3 (Good Health and Well-Being), followed by SDG 16 (Peace, Justice, and Strong Institutions) (TP:857) and SDG 9 (Industry, Innovation, and Infrastructure) (TP:214). It is possible for fake news to influence individual behaviours in a way that undermines the SDGs. For example, misinformation about vaccines can discourage people from getting vaccinated, undermining SDG 3 (Good Health and Well-being). SDG 16 aims to promote peace, justice, and strong institutions. By fostering social tensions, fuelling conflict, and undermining trust in institutions, fake news threatens to undermine this goal. As a result of fake news, trust in institutions is undermined, and peace and transparency are disrupted, resulting in chaos and anarchy. Fake news can significantly distort public understanding of important issues, often sensationalizing or trivializing matters that require serious attention. For example, By spreading denialism or downplaying climate change's severity, misinformation about SDG 13 (Climate Action) will undermine the goal. In light of Table 5  and the discussion on clustering research themes in fake news, one can observe the concentration of articles dealing with COVID-19, especially those mapped to SDG 3 (Good Health and Well-being) (Table 6  ). Research by Cinelli et al. Pennycook et al., and Loomba et al. [53 ,57 ,58 ]. underscore this focus, indicating acute academic attention toward health misinformation amidst a global pandemic. This is further emphasized by their high citation-per-year ratios, such as Loomba et al. [53 ], with 323 citations in a single year, indicative of the timely and societal relevance attributed to this subset of research. Fighting COVID-19 Misinformation on Social Media: Experimental Evidence for a Scalable Accuracy-Nudge Intervention.   4 Fake news in the era of generative AI Advancements in Artificial Intelligence (AI) have significantly simplified daily human activities. Developed by OpenAI and introduced in late 2022, the Chat Generative Pretrained Transformer (ChatGPT) serves as an exemplar of these AI technologies. ChatGPT operates as a text-based conversational agent, providing textual responses to user queries [59 ]. AI algorithms have been shown to be useful in detecting fake news or misinformation that may be interfering with efficiency and optimization [60 ,61 ]. Proponents of using AI in the detection of fake news suggest that certain principles need to be followed, including the development of strategies by the software designers to combat fake news, enabling software users to report fake news when detected, and keeping users informed of the dissemination of fake news [62 ]. For example, deep learning, machine learning, and natural language processing can extract text- or image-based cues to train models to aid in the prediction of the authenticity of news [2 ,63 ]. Alternatively, AI can be used to examine the social context of the news article, including features of the poster, such as the number of shares or retweets of the post [2 ]. However, Generative AI tools (GAI) like ChatGPT can also facilitate the spread of misinformation or fake news [64 ] to the detriment of those seeking information on virtually any topic, particularly health, finances, and politics. In extreme cases, the spread of misinformation through the use of AI-generated videos or written content can set factions against one another, with violence and death. To understand the scope of GAI tools in the spread of fake news, it's important to understand the difference between simply posting a query on a search engine as opposed to posting the same question to an AI-based chatbot. Asking search engines Google or Bing a question, such as “Are COVID vaccines safe?” will return a variety of sites that a user can then choose to peruse, many of which may contain false information but some of which may be accurate. Alternatively, with generative AI, the choice component is removed as the platform pools content from across various news sources and provides a single response to the requestor [65 ]. “At first glance, one has a self-contained answer that appears entirely trustworthy. But in truth, the reader has no idea if the source is the BBC, QAnon or a Russian bot, and no alternative views are provided” [65 ]. Goldstein et al. [66 ] discussed the manipulation of fake persona creation, AI-generated imagery, outsourcing, etc., that may cause false data interpretation toward career-oriented paths. Although OpenAI made promises, this new AI tool produces incorrect information more frequently and persuasively than its predecessor. NewsGuard found an 80–98 % probability of fake news on the generative AI sites ChatGPT and Bard [67 ]. While problematic in itself, the problem is confounded by the fact that users of generative AI technologies are often unable to distinguish true information from misinformation [68 ]. Additionally, the sources on which large language models are trained may be full of misinformation, leading the large language models to produce false content [61 ]. One of the most pressing concerns about Generative AI tools is about the accuracy and bias of the information generated by these models [69 ] to improve public health and advance scientific research [5 ]. There are also questions about the ownership and control of the data used to train these models and the potential for these models to exacerbate existing health disparities. Additionally, there is concern about the ability of these tools to protect sensitive health data [69 ]. GAI tools can generate compelling fake news and propaganda, which could be used to manipulate public opinion. Bioethics studies ethical, social, and legal issues in biomedicine and biomedical research. The ChatGPT has raised the same problems for bioethics as current medical AI. These include data ownership, consent for data use, data representativeness and bias, and privacy [70 ]. Similarly, GAI tools can manipulate financial decision-making [71 ]. Intending to raise their profits and harm other businesses, fake websites may be created or false information disseminated online that is then manipulated in AI models. People accessing this information to ask questions and receive answers related to financial decision-making may see their individual or business futures destroyed. Social bots may be created to post false information designed to benefit particular companies or organizations to the detriment of others [2 ,72 ]. Whether with financial information or another topic, social bots immediately increase engagement with information as soon as it is created to increase its perceived legitimacy and spread [2 ]. In addition, the bots target users who are most likely to share or repost the information, again with the goal of increasing the spread of the disinformation. The impact of GAI tools on the general public and research community is also a topic of discussion. There are concerns about the impact of LLMs on the research community, including the potential for these models to be used for plagiarism and the impact of preprints on disseminating research [6 ] and declaration of use of Generative AI tools for manuscript writing [73 ]. In this work by Grünebaum et al. [74 ], the authors have presented the advancements in natural language processing and how it can be applied to medicine, including the potential use of ChatGPT as a clinical tool. However, there are limitations to ChatGPT, including the possibility of producing seemingly credible but incorrect responses. It also discusses guidelines for using chatbots in medical publications and the implications of nonhuman “authors" on the integrity of scientific publications and medical knowledge. Amaro et al., 2023 have experimented with 62 university students who extensively employ ChatGPT. They collected the participants' perceptions of trust, satisfaction, and usability and the net promoter score (NPS). It is observed that usability and the NPS also resulted higher when the fake news was detected in the late interaction. The study also investigates whether early or late knowledge of this possibility affects user perceptions differently. They involved 62 participants who were randomly assigned to a control group or one of two treatment groups. The participants interacted with ChatGPT and answered questions about their perceptions of its trustworthiness, usability, and satisfaction. The study found that the occasional production of fake information by ChatGPT harmed user trust and satisfaction. Still, this effect was mitigated when users were informed of the possibility of counterfeiting details early on.  5 Emerging research topics based on prominence percentile Prominence is an indicator of the momentum or visibility of a particular research topic and has the potential to predict whether a topic will grow or decline in the near future. This is regardless of whether the topic is considered to be emergent or not [75 ]. The higher the momentum, the more funds per author available for research on that topic. A correlation exists between the prominence (momentum) of a particular topic and the amount of funding per author. It is calculated by weighing three metrics for papers clustered in a topic.• Citation Count in year n to papers published in n and n-1  • Scopus Views Count in year n to papers published in n and n-1  • Average CiteScore for year n    Table 7   shows the emerging research topics related to Fake news in the top 1 % Prominence Percentile (PP), with each topic having at least 50 publications.  . According to the top-cited article by Gandhi and Jain 2020 in Topic 1, Deepfake is an AI-synthesized application that produces entrancing counterfeit multimedia objects empowered by deep learning approaches. Deepfake was introduced in 2017 by a Reddit community user who swapped faces in the porn-graphics with Hollywood celebrities. Recently, deepfakes have become a growing concern in fields ranging from media integrity to personal privacy. A deepfake detector's role is to classify the deepfake as fake correctly. However, to fool the deepfake detector, Gandhi and Jain (2020) enhanced the capability of deepfake images using adversarial perturbation. Authors have utilized the Fast Gradient Sign Method and the Carlini and Wagner norm attack to create the adversarial perturbation. The experimental outcome suggests that the deepfake detectors achieved 75 % accuracy for unperturbed deepfakes, whereas the accuracy falls to 27 % with perturbed deepfakes. A highly cited article in Topic 2 concludes that in the wake of the COVID-19 pandemic, the public has witnessed a massive rise in fake news or disinformation about the unfamiliar disease. The malicious actors manipulate and present tampered information over the vulnerabilities of the pandemic. This falsity of the new pandemic spreads much faster than the pandemic itself, resulting in a situation of infodemic. This state of affairs leads to an overflow of credible and unreliable information, leaving the public confused. Naeem and Bhatti [76 ] highlighted how fighting with the infodemic is a new front during the outbreak. The authors have stressed busting the common myths, such as that consuming alcohol and eating garlic can protect from COVID-19, taking hot baths and spraying chlorine kills the coronavirus. Further, the situation was so vulnerable that Tedros Adhanom Ghebreyesus, WHO Director-General, said: ‘We're not just fighting an epidemic; we're fighting an infodemic. Technology has been critical in responding to the Coronavirus Disease (COVID-19) epidemic. Chamola et al. (2020), in topic 3, highlighted the role of several technologies, such as the Internet of Things (IoT), Unmanned Aerial Vehicles (UAVs), blockchain, Artificial Intelligence (AI), and 5G, to mitigate the impact of COVID-19. The Internet of Medical Things (IoMT), also called the healthcare IoT, played a crucial role in remote patient monitoring, telemedicine, etc. Maintaining social distance is an effective way of controlling the spread of the COVID-19 outbreak. The UAV drones ensure more accessible delivery of medical supplies to remote and unreachable locations with less or no interaction. Further, drones are deployed to monitor sensitive places for crowd surveillance. Similarly, the global positioning system (GPS) based on satellite navigation is helpful for tracking the real-time as well as the historical location of a person. To curb the spread of the disease using GPS location, India's Ministry of Electronics and IT (MeitY) has developed an app called Aarogya Setu. The prime objective of this app was contact tracing. However, besides identifying the various zones of an individual, this app was also invaluable for vaccine distribution. Likewise, in recent times, AI has been among the benchmark technological developments. AI can combat the aftermath of the virus, including disease surveillance, busting fake news, risk prediction, etc. Correspondingly, blockchain has a considerable role in boosting the modern healthcare system, including patient traceability, encrypted storage and retrieval of electronic health records, etc. Another recent study in Topic 4, according to Loomba et al. (2021), concludes that nearly 3 % of all COVID-19 vaccine-related articles offer at least one disinformation regarding the vaccine. Further, the volume of such misleading studies has rapidly increased in recent years. Loomba et al. [53 ] conducted a trial in the UK and the USA to quantify the disinformation and myth about the impact of vaccines. The authors also observed a decline in vaccine acceptance due to the perception of herd immunity and the long-term side effects of vaccines. Further, scientific-sounding misinformation, such as the virus has emerged from 5G mobile networks and a trial participant has died after vaccination, were more strongly linked with a decline in vaccination acceptance. The dataset's size and quality significantly impact the model's accuracy and prediction ability, according to Wang (2017) under topic 5. The vast amounts of data result in a more accurate machine-learning model. The existing statistical models are proven to be less effective in combating fake news detection due to the absence of labeled benchmark datasets. Wang [21 ] suggested a ‘LIAR' data set consisting of 12.8K human-labeled short words, significantly the largest dataset. Finally, the author underlined that amalgamating meta-data with text improves automatic fake news detection. In topic 6, Vosoughi et al. [77 ] confirmed that with the emergence of social media, fake news has rapidly evolved. Fake news is fabricated content intentionally published and propagated through various social media. A study has been conducted to understand the speed with which fake news spreads. Vosoughi et al. [77 ] analyzed a data set of rumour cascades on Twitter from 2006 to 2017. Authors identified that the top 1 % of fake news spreads between 1000 and 10,000 people in a certain period. However, the true news is that it hardly reaches 1000 people during the same span. Therefore, it can be judiciously concluded that the lies spread faster than the truth. In topic 7, the study by Lewandowsky et al. (2013) deals with the fact that the impact of science denial can also be seen beyond COVID-19. Certain people remain unconvinced about the changes in the world's climate due to carbon dioxide, childhood vaccination, etc. Lewandowsky et al. [78 ] found that conspiracy beliefs are one of the most contributory aspects of science skepticism and rejection of science. Authors have surveyed the climate-blog visitors to understand the logic behind the acceptance and rejection of climate science. The common public remains dubious by the testimony of science. It has been observed that apart from conspiracist thinking, endorsement of free markets is also one of the significant factors behind this rejection. We live in a time and society of uncertainty that readily accepts fake news and rejects science without hesitancy. Scheufele and Krause [79 ] surveyed how sociocultural circumstances undermine the belief of the common public in science. From the ages, detachment between common public impression and scientific consent remains prevalent, including vaccine safety, climate change, etc. The primary cause of this disconnection between the public and science is the dissemination of misinformation and disinformation by the media houses and political environments. Therefore, epistemic knowledge, including information and disinformation on a specific topic, is far more crucial to making an impression. 5.1 Keyphrases of emerging topics Next, we summarize the keyphrases under each of the emerging topics. Several studies have used keyphrases analysis to identify research hotspots for a research theme [30, [80 ]. SciVal allows the extraction of top keyphrases by text mining from titles and abstracts of articles. Fig. 5  a to h shows the keyphrases for each of the eight emerging topics. The top keyphrases are “Fake Detection”, “COVID-19”, “Disinformation”, “Vaccine Hesitancy” and “Climate Change”.   6 Conclusions Fake news impairs decision-making since it leads to biases in information interpretation. People tend to accept negative information irrespective of its impact since it increases their attention and arousal. However, positive news has a less significant effect on the human psyche. In the evolving landscape of fake news research, understanding the factors that contribute to the field's research performance becomes critical. Firstly, the surge in academic interest in fake news coincides with the emergence of the COVID-19 pandemic, illuminating the role of a contemporary crisis in shaping research agendas. Secondly, the analysis reveals a geographical concentration of research output, predominantly from U.S.-based institutions like MIT, thereby emphasizing the need for a more globally diverse academic contribution. Thirdly, the role of specific journals, such as the Journal of Medical Internet Research  and PLoS ONE , as platforms for impactful work in this area is evident. Lastly, international collaborations stand out for generating the most impactful publications, as indicated by the highest citation impacts. The keyword co-occurrence analysis identifies three distinct clusters of research in the domain of fake news. Cluster 1 emphasizes the role of social media and traditional journalism in perpetuating disinformation, underscoring the need for media literacy interventions. Cluster 2 highlights the utility of machine learning and natural language processing for fake news detection, accentuating the technological arms race in combating deceptive content. Cluster 3 focuses on the COVID-19 ″infodemic," revealing both the gravity and the breadth of misinformation amid global crises. The clusters illustrate an intricate web of challenges ranging from technological to psychological and societal. Their collective implication highlights the urgency of multi-disciplinary approaches to counteract the sophisticated and pervasive nature of fake news. For the first time, direct mapping of fake news to SDGs was conducted. Despite the heavy focus on SDG 3, especially concerning the health misinformation perpetuated during the COVID-19 pandemic, other SDGs are also well-represented (SDG 16, 9, 10). Research on SDG 16 reveals the broader social implications of fake news, particularly how it undermines peace, justice, and strong institutions. Furthermore, SDG 9, focusing on Industry, Innovation, and Infrastructure, also indicates an academic interest in technological approaches to combating disinformation. SDG 10, focused on reduced inequalities, suggests an understanding of the socio-economic dimensions of misinformation. For the first time, our study used the metric of Prominence percentile for identifying the most salient and urgently discussed topics related to fake news. For instance, the high prominence of topics such as “Object Detection in Deep Learning" and “COVID-19; Psychological Support; Mindfulness" indicates not only scientific but also economic prioritization. The notable prominence of topics related to misinformation and public sentiment, such as “Rumour; Social Media; Disinformation," underscores the critical need for research into ethical frameworks and computational tools for information verification. The prevalence of large language models like ChatGPT in various domains, from healthcare to information dissemination, is undeniable. While they show promise in democratizing access to information and aiding in research, ethical and accuracy-related challenges loom large. Notably, the models' capacity for generating misleading or false information raises ethical concerns, such as in the realm of fake news generation. The consequence extends from eroding trust in AI systems to affecting user perceptions, as corroborated by empirical studies. Additionally, personal harm can befall users as misinformation about health and finances, among other things, is generated and disseminated. Data ownership, user consent, and representational bias are additional layers of complexity in this discourse. Therefore, it is crucial to address these issues comprehensively for the responsible and equitable application of these potent tools in diverse sectors. There is a need for future research to focus on the characteristics of individuals that lead them to be drawn to fake news [81 ]. It would be interesting for researchers to examine further the personality characteristics that may make some people more likely to believe and spread fake news than others. This could involve examining factors such as persuasibility, influenceability, and other traits that have been studied in past. It would also be interesting for future research to examine personality characteristics that lead individuals to be drawn to generative AI techniques and for what purpose. Are some people blanket users of generative AI tools, whereas others are more selective users? What distinguishes the two, and how do those distinguishing features relate to the consumption of fake news? It is also worth considering why fake news and disinformation only began to receive significant attention in the research literature in 2012, despite the widespread use of social media for several years prior. It is possible that there were specific events or circumstances in countries such as the US, UK, and India that prompted the sudden emergence of research on this topic. Further research could explore the factors that may have led to the increased interest in fake news and disinformation and how they relate to the rise of social media and other technological developments. Emerging economies that are seeing higher adoption of internet technologies should also be the focus of future research [82 ]. In scrutinizing the landscape of fake news research, several limitations must be acknowledged. First, the exclusive use of bibliometric data may not capture the full scope of scholarly activity, as grey literature, internal reports, and methodological papers often go unindexed. This omission could potentially skew the representation of research priorities. Second, bibliometric indicators such as citation counts and Scopus Views Count inherently favor well-established fields over nascent areas of study, possibly underestimating the prominence of emerging topics. Fourth, the methodology does not account for the multi-disciplinary nature of SDGs, possibly leading to an incomplete or biased mapping of the publications to SDGs.  Data availability statement Data will be made available on reasonable request. Data associated with our study has not been deposited into a publicly available repository.  Funding statement This research received no specific grant from funding agencies in the public, commercial, or not-for-profit sectors.  CRediT authorship contribution statement Raghu Raman:  Writing – review & editing, Writing – original draft, Conceptualization. Vinith Kumar Nair:  Writing – review & editing, Methodology, Investigation, Data curation. Prema Nedungadi:  Writing – review & editing, Writing – original draft. Aditya Kumar Sahu:  Writing – review & editing, Investigation. Robin Kowalski:  Writing – review & editing, Writing – original draft. Sasangan Ramanathan:  Writing – review & editing. Krishnashree Achuthan:  Writing – review & editing, Writing – original draft, Methodology, Investigation, Conceptualization.   Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.  Acknowledgements We want to express our immense gratitude to our beloved Chancellor, Mata Amritanandamayi Devi (AMMA), for providing the motivation and inspiration for this research work.   References [1] A.D. Gordon  J.M. Kittross  J.C. Merrill  W.A. Babcock  M. Dorsher  J.A. Armstrong   J.B. Singer   Infotainment, sensationalism, and “reality”   Controversies in Media Ethics  2012 Routledge   432 458    Gordon, A. D., Kittross, J. M., Merrill, J. C., Babcock, W. A., Dorsher, M., Armstrong, J. A., ... & Singer, J. B. (2012). Infotainment, Sensationalism, and “Reality”. In Controversies in Media Ethics (pp. 432-458). Routledge.  [2] E. Aimeur  S. Amri  G. Brassard   Fake news, disinformation, and misinformation: a review   Social Network Analysis and Mining  13  2023    Aimeur, E., Amri, S., & Brassard, G. (2023). Fake news, disinformation, and misinformation: A review. Social Network Analysis and Mining, 13. https://doi.org/10.1007.s13278-023-01028-5  [3] W.M. Lim   Fact or fake? The search for truth in an infodemic of disinformation, misinformation, and malinformation with deepfake and fake news   J. Strat. Market.   2023  10.1080/09625254X.2023.2253805   Lim, W. M.. (2023). Fact or fake? The search for truth in an infodemic of disinformation, misinformation, and malinformation with deepfake and fake news. Journal of Strategic Marketing. https://doi.org/10.1080/09625254X.2023.2253805  [4] I. Amaro  P. Barra  A. Della Greca  R. Francese  C. Tucci   Believe in artificial intelligence? A user study on the ChatGPT's fake information impact   IEEE Transactions on Computational Social Systems   2023    Amaro, I., Barra, P., Della Greca, A., Francese, R., & Tucci, C. (2023). Believe in Artificial Intelligence? A User Study on the ChatGPT's Fake Information Impact. IEEE Transactions on Computational Social Systems.  [5] L. De Angelis  F. Baglivo  G. Arzilli  G.P. Privitera  P. Ferragina  A.E. Tozzi  C. Rizzo   ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health   Front. Public Health  11  2023  1166120   De Angelis, L., Baglivo, F., Arzilli, G., Privitera, G. P., Ferragina, P., Tozzi, A. E., & Rizzo, C. (2023). ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health. Frontiers in Public Health, 11, 1166120.  [6] M. Dadkhah  M.H. Oermann  H. Mihály  R. Raman  L.D. Dávid   Detection of Fake Papers in the Era of Artificial Intelligence   2023 Diagnosis     Dadkhah, M., Oermann, M. H., Mihaly, H., Raman, R., & David, L. D. (2023). Detection of fake papers in the era of artificial intelligence. Diagnosis, (0).  [7] L.R.D. Kosnik   Refusing to budge: a confirmatory bias in decision making?   Mind Soc.  7  2 2008  193 214    Kosnik, L. R. D. (2008). Refusing to budge: a confirmatory bias in decision making?. Mind & Society, 7(2), 193-214.  [8] C.K. Lai  K.M. Hoffman  B.A. Nosek   Reducing implicit prejudice   Social and Personality Psychology Compass  7  5 2013  315 330    Lai, C. K., Hoffman, K. M., & Nosek, B. A. (2013). Reducing implicit prejudice. Social and Personality Psychology Compass, 7(5), 315-330.  [9] J. LeDoux   Rethinking the emotional brain   Neuron  73  4 2012  653 676    LeDoux, J. (2012). Rethinking the emotional brain. Neuron, 73(4), 653-676.  [10] N. Nour  J. Gelfand   Deepfakes: a digital transformation leads to misinformation   The Gray Journal  18  2 2022  85 94  10.26069/greynet-2022-000.471-gg   Nour, N., & Gelfand, J. (2022). Deepfakes: A digital transformation leads to misinformation. The Gray Journal, 18(2), 85-94. https://doi.org/10.26069/greynet-2022-000.471-gg  [11] Y. Tsfati  H.G. Boomgaarden  J. Strömbäck  R. Vliegenthart  A. Damstra  E. Lindgren   Causes and consequences of mainstream media dissemination of fake news: literature review and synthesis   Annals of the International Communication Association  44  2 2020  157 173    Tsfati, Y., Boomgaarden, H. G., Stromback, J., Vliegenthart, R., Damstra, A., & Lindgren, E. (2020). Causes and consequences of mainstream media dissemination of fake news: literature review and synthesis. Annals of the International Communication Association, 44(2), 157-173.  [12] E.C. Tandoc Jr.   The facts of fake news: a research review   Sociology Compass  13  9 2019  e12724   Tandoc Jr, E. C. (2019). The facts of fake news: A research review. Sociology Compass, 13(9), e12724  [13] J.P. Baptista  A. Gradim   Understanding fake news consumption: a review   Soc. Sci.  9  10 2020  185    Baptista, J. P., & Gradim, A. (2020). Understanding fake news consumption: A review. Social Sciences, 9(10), 185.  [14] A.E. Marwick   Why do people share fake news? A sociotechnical model of media effects   Georgetown law technology review  2  2 2018  474 512    Marwick, A. E. (2018). Why do people share fake news? A sociotechnical model of media effects. Georgetown law technology review, 2(2), 474-512.  [15] B. Gunawan  B.M. Ratmono  A.G. Abdullah  N. Sadida  H. Kaprisma   Research mapping in the use of technology for fake news detection: bibliometric analysis from 2011 to 2021   Indonesian Journal of Science and Technology  7  3 2022  471 496    Gunawan, B., Ratmono, B. M., Abdullah, A. G., Sadida, N., & Kaprisma, H. (2022). Research mapping in the use of technology for fake news detection: Bibliometric analysis from 2011 to 2021. Indonesian Journal of Science and Technology, 7(3), 471-496.  [16] K. Bryanov  V. Vziatysheva   Determinants of individuals' belief in fake news: a scoping review determinants of belief in fake news   PLoS One  16  6 2021  e0253717   Bryanov K, Vziatysheva V (2021) Determinants of individuals' belief in fake news: A scoping review determinants of belief in fake news. PLoS ONE 16(6): e0253717.  [17] R. Soler-Costa  P. Lafarga-Ostáriz  M. Mauri-Medrano  A.J. Moreno-Guerrero   Netiquette: ethic, education, and behavior on internet—a systematic literature review   Int. J. Environ. Res. Publ. Health  18  3 2021  1212    Soler-Costa, R., Lafarga-Ostariz, P., Mauri-Medrano, M., & Moreno-Guerrero, A. J. (2021). Netiquette: Ethic, education, and behavior on internet-a systematic literature review. International journal of environmental research and public health, 18(3), 1212.  [18] E. Hagg  V.S. Dahinten  L.M. Currie   The emerging use of social media for health-related purposes in low and middle-income countries: a scoping review   Int. J. Med. Inf.  115  2018  92 105    Hagg, E., Dahinten, V. S., & Currie, L. M. (2018). The emerging use of social media for health-related purposes in low and middle-income countries: A scoping review. International journal of medical informatics, 115, 92-105.  [19] T. Simon  A. Goldberg  B. Adini   Socializing in emergencies—a review of the use of social media in emergency situations   Int. J. Inf. Manag.  35  5 2015  609 619    Simon, T., Goldberg, A., & Adini, B. (2015). Socializing in emergencies-A review of the use of social media in emergency situations. International journal of information management, 35(5), 609-619.  [20] Y.J. Li  C.M. Cheung  X.L. Shen  M.K. Lee   Health misinformation on social media: a literature review   PACIS 2019 Proceedings   2019  194    Li, Y. J., Cheung, C. M., Shen, X. L., & Lee, M. K. (2019). Health misinformation on social media: a literature review. PACIS 2019 Proceedings. 194  [21] Y. Wang  M. McKee  A. Torbica  D. Stuckler   Systematic literature review on the spread of health-related misinformation on social media   Soc. Sci. Med.  240  2019  112552   Wang, Y., McKee, M., Torbica, A., & Stuckler, D. (2019). Systematic literature review on the spread of health-related misinformation on social media. Social science & medicine, 240, 112552.  [22] Y.M. Rocha  G.A. de Moura  G.A. Desidério  C.H. de Oliveira  F.D. Lourenço  L.D. de Figueiredo Nicolete   The impact of fake news on social media and its influence on health during the COVID-19 pandemic: a systematic review   J. Publ. Health   2021  1 10    Rocha, Y. M., de Moura, G. A., Desiderio, G. A., de Oliveira, C. H., Lourenco, F. D., & de Figueiredo Nicolete, L. D. (2021). The impact of fake news on social media and its influence on health during the COVID-19 pandemic: A systematic review. Journal of Public Health, 1-10.  [23] J. Alvarez-Galvez  V. Suarez-Lledo  A. Rojas-Garcia   Determinants of infodemics during disease outbreaks: a systematic review   Front. Public Health  9  2021  603603   Alvarez-Galvez, J., Suarez-Lledo, V., & Rojas-Garcia, A. (2021). Determinants of infodemics during disease outbreaks: a systematic review. Frontiers in public health, 9, 603603.  [24] V. Suarez-Lledo  J. Alvarez-Galvez   Prevalence of health misinformation on social media: systematic review   J. Med. Internet Res.  23  1 2021  e17187   Suarez-Lledo, V., & Alvarez-Galvez, J. (2021). Prevalence of health misinformation on social media: systematic review. Journal of medical Internet research, 23(1), e17187.  [25] G.J. Ling  A. Yaacob  R.A. Latif   A bibliometric analysis on the influence of social media during the COVID-19 pandemic   SEARCH Journal of Media and Communication Research  13  3 2021  35 55    Ling, G. J., Yaacob, A., & Latif, R. A. (2021). A bibliometric analysis on the influence of social media during the COVID-19 pandemic. SEARCH Journal of Media and Communication Research, 13(3), 35-55.  [26] E. Gabarron  S.O. Oyeyemi  R. Wynn   COVID-19-related misinformation on social media: a systematic review   Bull. World Health Organ.  99  6 2021  455    Gabarron, E., Oyeyemi, S. O., & Wynn, R. (2021). COVID-19-related misinformation on social media: a systematic review. Bulletin of the World Health Organization, 99(6), 455.  [27] M. Akram  A. Nasar  A. Arshad-Ayaz   A bibliometric analysis of disinformation through social media   Online J. Commun. Media Technol.  12  4 2022  e202242   Akram, M., Nasar, A., & Arshad-Ayaz, A. (2022). A bibliometric analysis of disinformation through social media. Online Journal of Communication and Media Technologies, 12(4), e202242.  [28] K. Achuthan  V.K. Nair  R. Kowalski  S. Ramanathan  R. Raman   Cyberbullying research—alignment to sustainable development and impact of COVID-19: bibliometrics and science mapping analysis   Comput. Hum. Behav.  140  2023  107566   Achuthan, K., Nair, V. K., Kowalski, R., Ramanathan, S., & Raman, R. (2023). Cyberbullying research-Alignment to sustainable development and impact of COVID-19: Bibliometrics and science mapping analysis. Computers in Human Behavior, 140, 107566.  [29] R. Raman  N. Subramaniam  V.K. Nair  A. Shivdas  K. Achuthan  P. Nedungadi   Women entrepreneurship and sustainable development: bibliometric analysis and emerging research trends   Sustainability  14  15 2022  9160    Raman R, Subramaniam N, Nair VK, Shivdas A, Achuthan K, Nedungadi P. Women entrepreneurship and sustainable development: bibliometric analysis and emerging research trends. Sustainability. 2022 ;14(15):9160.  [30] R. Raman  V.K. Nair  V. Prakash  A. Patwardhan  P. Nedungadi   Green-hydrogen research: what have we achieved, and where are we going? Bibliometrics analysis   Energy Rep.  8  2022  9242 9260    Raman R, Nair VK, Prakash V, Patwardhan A, Nedungadi P. Green-hydrogen research: What have we achieved, and where are we going? Bibliometrics analysis. Energy Reports. 2022 ;8:9242-9260.  [31] B. Jayabalasingham  R. Boverhof  K. Agnew  L. Klein   Identifying research supporting the United Nations sustainable development goals   Mendeley Data  1  2019  1    Jayabalasingham, B., Boverhof, R., Agnew, K., & Klein, L. (2019). Identifying research supporting the United Nations sustainable development goals. Mendeley Data, 1, 1.  [32] Naveen Donthu  Satish Kumar  Debmalya Mukherjee  Nitesh Pandey  Marc Lim Weng   How to conduct a bibliometric analysis: an overview and guidelines   J. Bus. Res.  133  2021  285 296   ISSN 0148-2963  Naveen Donthu, Satish Kumar, Debmalya Mukherjee, Nitesh Pandey, Weng Marc Lim, how to conduct a bibliometric analysis: An overview and guidelines, Journal of Business Research, Volume 133, 2021, Pages 285-296, ISSN 0148-2963.  [33] N. Donthu  S. Kumar  D. Mukherjee  N. Pandey  W.M. Lim   How to conduct a bibliometric analysis: an overview and guidelines   J. Bus. Res.  133  2021  285 296    Donthu, N., Kumar, S., Mukherjee, D., Pandey, N., & Lim, W. M. (2021). How to conduct a bibliometric analysis: An overview and guidelines. Journal of business research, 133, 285-296.  [34] K. Sau  Y. Nayak   Scopus based bibliometric and scientometric analysis of occupational therapy publications from 2001 to 2020 [version 1; peer review: 1 approved with reservations]   F1000Research  11  2022  155    Sau K and Nayak Y. Scopus based bibliometric and scientometric analysis of occupational therapy publications from 2001 to 2020 [version 1; peer review: 1 approved with reservations]. F1000Research 2022, 11:155  [35] R.K. Patra  N. Pandey  D. Sudarsan   Bibliometric analysis of fake news indexed in Web of Science and Scopus   Global Knowledge, Memory and Communication    2022  2001 2020   ahead-of-print No. ahead-of-print  Patra, R.K., Pandey, N. and Sudarsan, D. (2022), Bibliometric analysis of fake news indexed in Web of Science and Scopus (2001-2020), Global Knowledge, Memory and Communication, Vol. ahead-of-print No. ahead-of-print.  [36] D.D. Chaudhari  A.V. Pawar   Propaganda analysis in social media: a bibliometric review   Information Discovery and Delivery  49  1 2021  57 70    Chaudhari, D. D., & Pawar, A. V. (2021). Propaganda analysis in social media: a bibliometric review. Information Discovery and Delivery, 49(1), 57-70.  [37] N.J. van Eck  L. Waltman   Software survey: VOSviewer, a computer program for bibliometric mapping   Scientometrics  84  2 2010  523 538    van Eck, N. J., & Waltman, L. (2010). Software survey: VOSviewer, a computer program for bibliometric mapping. Scientometrics, 84(2), 523-538.  [38] L. Ha  L. Andreu Perez  R. Ray   Mapping recent development in scholarship on fake news and misinformation, 2008 to 2017: disciplinary contribution, topics, and impact   Am. Behav. Sci.  65  2 2021  290 315    Ha, L., Andreu Perez, L., & Ray, R. (2021). Mapping recent development in scholarship on fake news and misinformation, 2008 to 2017: Disciplinary contribution, topics, and impact. The American Behavioral Scientist, 65(2), 290-315.  [39] Y. Ding  Y. Wang  Y. Wang   It's Time to Confront Fake News and Rumors on Social Media: A Bibliometric Study Based on VOSviewer   2021 2021 IEEE 4th International Conference on Computer and Communication Engineering Technology (CCET)   226 232    Ding, Y., Wang, Y., & Wang, Y. (2021). It's time to confront fake news and rumors on social media: A bibliometric study based on VOSviewer. 2021 IEEE 4th International Conference on Computer and Communication Engineering Technology (CCET), 226-232.  [40] J. Pool  F. Fatehi  S. Akhlaghpour   Infodemic, misinformation and disinformation in pandemics: scientific landscape and the road ahead for public health informatics research   Stud. Health Technol. Inf.  281  2021  764 768    Pool, J., Fatehi, F., & Akhlaghpour, S. (2021). Infodemic, misinformation and disinformation in pandemics: Scientific landscape and the road ahead for public health informatics research. Studies in Health Technology and Informatics, 281, 764-768.  [41] Guillaume Roberge  Yury Kashnitsky  Chris James   “Elsevier 2022 Sustainable Development Goals (SDG) Mapping”   2022 Elsevier Data Repository   10.17632/6bjy52jkm9.1  vol. 1  Roberge, Guillaume; Kashnitsky, Yury; James, Chris (2022), “Elsevier 2022 Sustainable Development Goals (SDG) Mapping”, Elsevier Data Repository, V1, doi: 10.17632/6bjy52jkm9.1  [42] J. Paul  W.M. Lim  A. O'Cass  A.W. Hao  S. Bresciani   Scientific procedures and rationales for systematic literature reviews (SPAR-4-SLR)   Int. J. Consum. Stud.  45  2021  O1 O16    Paul J, Lim WM, O'Cass A, Hao AW, Bresciani S. Scientific procedures and rationales for systematic literature reviews (SPAR-4-SLR). Int J Consum Stud. 2021;45:O1-O16  [43] J. Renstrom   How Science Itself Fuels a Culture of Misinformation   2022, June 4   Thewire.In https://science.thewire.in/the-sciences/how-science-fuels-misinformation-culture/    Renstrom, J. (2022, June 4). How science itself fuels a culture of misinformation. Thewire.In. https://science.thewire.in/the-sciences/how-science-fuels-misinformation-culture/  [44] M. Aria  C. Cuccurullo   bibliometrix: an R-tool for comprehensive science mapping analysis   Journal of Informetrics  11  4 2017  959 975  10.1016/j.joi.2017.08.007   Aria, M. & Cuccurullo, C. (2017). bibliometrix: an R-tool for comprehensive science mapping analysis. Journal of Informetrics, 11(4), 959-975. https://doi.org/10.1016/j.joi.2017.08.007  [45] I. Zupic  T. Čater   Bibliometric methods in management and organization   Organ. Res. Methods  18  3 2015  429 472  10.1177/1094428114562629   Zupic, I. & Cater, T. (2015). Bibliometric methods in management and organization. Organizational Research Methods, 18(3), 429-472. https://doi.org/10.1177/1094428114562629  [46] P.C.D. Silva   Pandemic metaphors: bibliometric study of the COVID-19 (co) llateral effects   Research, Society and Development  9  11 2020    Silva, P. C. D. (2020). Pandemic metaphors: bibliometric study of the COVID-19 (co) llateral effects. Research, Society and Development, 9(11), e7809119636-e7809119636.  [47] L. Howell   Digital wildfires in a hyperconnected world   WEF Report 2013 https://www.weforum.org/reports/world-economic-forum-global-risks-2013-eighth-edition/ 2013    Howell L (2013) Digital wildfires in a hyperconnected world. WEF Report 2013. https://www.weforum.org/reports/world-economic-forum-global-risks-2013-eighth-edition/  [48] M. Del Vicario  A. Bessi  F. Zollo  F. Petroni  A. Scala  G. Caldarelli   W. Quattrociocchi   The spreading of misinformation online   Proc. Natl. Acad. Sci. USA  113  3 2016  554 559    Del Vicario, M., Bessi, A., Zollo, F., Petroni, F., Scala, A., Caldarelli, G., ... & Quattrociocchi, W. (2016). The spreading of misinformation online. Proceedings of the National Academy of Sciences, 113(3), 554-559.  [49] S.J. Frenda  R.M. Nichols  E.F. Loftus   Current issues and advances in misinformation research   Curr. Dir. Psychol. Sci.  20  1 2011  20 23    Frenda SJ, Nichols RM, Loftus EF (2011) Current issues and advances in misinformation research. Curr Dir Psychol Sci 20(1):20-23  [50] A. Zubiaga  A. Aker  K. Bontcheva    Detection and resolution of rumours in social media: a survey   ACM Comput. Surv.  51  2 2018  32   ISSN 0360-0300  Zubiaga, A., Aker, A., Bontcheva, K. orcid.org/0000-0001-6152-9600 et al. (2 more authors) (2018) Detection and Resolution of Rumours in Social Media: A Survey. ACM Computing Surveys, 51 (2). 32. ISSN 0360-0300  [51] A. Rossler   2019 ieee/cvf international conference on computer vision (iccv)   Faceforensics: Learning to Detect Manipulated Facial Images   2019  1 11    Rossler, A. (2019). 2019 Ieee/cvf International Conference on Computer Vision (iccv). Faceforensics: Learning to Detect Manipulated Facial Images, 1-11.  [52] N. Ruchansky  S. Seo  Y. Liu   Csi: a hybrid deep model for fake news detection   Proceedings of the 2017 ACM on Conference on Information and Knowledge Management  2017, November  797 806    Ruchansky, N., Seo, S., & Liu, Y. (2017, November). Csi: A hybrid deep model for fake news detection. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (pp. 797-806).  [53] S. Loomba  A. de Figueiredo  S.J. Piatek  K. de Graaf  H.J. Larson   Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA   Nat. Human Behav.  5  3 2021  337 348    Loomba, S., de Figueiredo, A., Piatek, S. J., de Graaf, K., & Larson, H. J. (2021). Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA. Nature human behaviour, 5(3), 337-348.  [54] M. Sallam  D. Dababseh  H. Eid  K. Al-Mahzoum  A. Al-Haidar  D. Taim   A. Mahafzah   High rates of COVID-19 vaccine hesitancy and its association with conspiracy beliefs: a study in Jordan and Kuwait among other Arab countries   Vaccines  9  1 2021  42    Sallam, M., Dababseh, D., Eid, H., Al-Mahzoum, K., Al-Haidar, A., Taim, D., ... & Mahafzah, A. (2021). High rates of COVID-19 vaccine hesitancy and its association with conspiracy beliefs: a study in Jordan and Kuwait among other Arab countries. Vaccines, 9(1), 42.  [55] A. Kata   Anti-vaccine activists, Web 2.0, and the postmodern paradigm–An overview of tactics and tropes used online by the anti-vaccination movement   Vaccine  30  25 2012  3778 3789    Kata, A. (2012). Anti-vaccine activists, Web 2.0, and the postmodern paradigm-An overview of tactics and tropes used online by the anti-vaccination movement. Vaccine, 30(25), 3778-3789.  [56] H.J. Larson  L.Z. Cooper  J. Eskola  S.L. Katz  S. Ratzan   Addressing the vaccine confidence gap   Lancet  378  9790 2011  526 535    Larson, H. J., Cooper, L. Z., Eskola, J., Katz, S. L., & Ratzan, S. (2011). Addressing the vaccine confidence gap. The Lancet, 378(9790), 526-535.  [57] M. Cinelli  W. Quattrociocchi  A. Galeazzi  C.M. Valensise  E. Brugnoli  A.L. Schmidt   A. Scala   The COVID-19 social media infodemic   Sci. Rep.  10  1 2020  1 10    Cinelli, M., Quattrociocchi, W., Galeazzi, A., Valensise, C. M., Brugnoli, E., Schmidt, A. L., ... & Scala, A. (2020). The COVID-19 social media infodemic. Scientific reports, 10(1), 1-10.  [58] G. Pennycook  J. McPhetres  Y. Zhang  J.G. Lu  D.G. Rand   Fighting COVID-19 misinformation on social media: experimental evidence for a scalable accuracy-nudge intervention   Psychol. Sci.  31  7 2020  770 780    Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., & Rand, D. G. (2020). Fighting COVID-19 misinformation on social media: Experimental evidence for a scalable accuracy-nudge intervention. Psychological science, 31(7), 770-780.  [59] OpenAI   Optimizing Language models for dialogue   https://openai.com/blog/chatgpt/     OpenAI, ChatGPT: Optimizing Language Models for Dialogue. https://openai.com/blog/chatgpt/; accessed 23 August 2023  [60] P. Akhtar  A.M. Ghouri  H.U.R. Khan  M. Amin ul Haq  U. Awan  N. Zahoor  Z. Khan  A. Ashraf   Detecting fake news and disinformation using artificial intelligence and machine learning to avoid supply chain disruptions   Ann. Oper. Res.  327  2 2023  633 657   https://doi-org.libproxy.clemson.edu/10.1007/s10479-022-05015-5    Akhtar, P., Ghouri, A. M., Khan, H. U. R., Amin ul Haq, M., Awan, U., Zahoor, N., Khan, Z., & Ashraf, A. (2023). Detecting fake news and disinformation using artificial intelligence and machine learning to avoid supply chain disruptions. Annals of Operations Research, 327(2), 633-657. https://doi-org.libproxy.clemson.edu/10.1007/s10479-022-05015-5  [61] A. Montoro-Montarroso  J. Cantón-Correa  P. Rosso  B. Chulvi  Á. Panizo-Lledot  J. Huertas-Tato  B. Calvo-Figueras  M. José Rementeria  J. Gómez-Romero   Fighting disinformation with artificial intelligence: fundamentals, advances and challenges   El Prof. Inf.  32  3 2023  1 16   https://doi-org.libproxy.clemson.edu/10.3145/epi.2023.may.22    Montoro-Montarroso, A., Canton-Correa, J., Rosso, P., Chulvi, B., Panizo-Lledot, A., Huertas-Tato, J., Calvo-Figueras, B., Jose Rementeria, M., & Gomez-Romero, J. (2023). Fighting disinformation with artificial intelligence: fundamentals, advances and challenges. El Profesional de La Informacion, 32(3), 1-16. https://doi-org.libproxy.clemson.edu/10.3145/epi.2023.may.22  [62] G. Wellner  D. Mykhailov   Caring in an algorithmic world: ethical perspectives for designers and developers in building AI algorithms to fight fake news   Sci. Eng. Ethics  29  4 2023  30   https://doi-org.libproxy.clemson.edu/10.1007/s11948-023-00450-4    Wellner, G., & Mykhailov, D. (2023). Caring in an Algorithmic World: Ethical Perspectives for Designers and Developers in Building AI Algorithms to Fight Fake News. Science and Engineering Ethics, 29(4), 30. https://doi-org.libproxy.clemson.edu/10.1007/s11948-023-00450-4  [63] B. Kim  A. Xiong  D. Lee  K. Han   A systematic review on fake news research through the lens of news creation and consumption: research efforts, challenges, and future directions   PLoS One  16  12 2021  e0260080 10.1371/journal.pone.0260080   Kim, B., Xiong, A., Lee, D., Han, K. (2021). A systematic review on fake news research through the lens of news creation and consumption: Research efforts, challenges, and future directions. PLoS ONE 16(12). e0260080. https://doi.org/10.1371/journal.pone.0260080  [64] D. Shin  K.F. Kee   Editorial note for special issue on Al and fake news, mis(dis)information, and algorithmic bias   J. Broadcast. Electron. Media  67  3 2023  241 245   https://doi-org.libproxy.clemson.edu/10.1080/08838151.2023.2225665    Shin, D., & Kee, K. F. (2023). Editorial Note for Special Issue on Al and Fake News, Mis(dis)information, and Algorithmic Bias. Journal of Broadcasting & Electronic Media, 67(3), 241-245. https://doi-org.libproxy.clemson.edu/10.1080/08838151.2023.2225665  [65] J. Cecil   April/May). Can you believe it?   World Today   2023    Cecil, J. (2023, April/May). Can you believe it? The World Today.  [66] J.A. Goldstein  R. DiResta   Research note: this salesperson does not exist: how tactics from political influence operations on social media are deployed for commercial lead generation   Harvard Kennedy School (HKS) Misinformation Review  3  5 2022    Goldstein, J. A., & DiResta, R. (2022). Research note: This salesperson does not exist: How tactics from political influence operations on social media are deployed for commercial lead generation. Harvard Kennedy School (HKS) Misinformation Review, 3(5).  [67] AI Chatbots Spreading Fake News? ChatGPT, Google Bard Producing News-Related Misinformation, Finds Report  2023 Technology    https://www.latestly.com/technology/    AI chatbots spreading fake news? ChatGPT, Google Bard producing news-related misinformation, finds report. August 16, 2023. Technology. https://www.latestly.com/technology/  [68] J. Laird   ChatGPT makes spotting fake news impossible for most people   https://tech.co/news/chatgpt-spotting-fake-news-impossible#:∼:text=The%20survey%20found%20that%20not,them%20when%20they%20were%20false 2023, June 29    Laird, J. (2023, June 29). ChatGPT makes spotting fake news impossible for most people. https://tech.co/news/chatgpt-spotting-fake-news-impossible#:∼:text=The%20survey%20found%20that%20not,them%20when%20they%20were%20false.  [69] WHO cautions against the usage of AI chatbots like ChatGPT, Bard in healthcare. (May 16, 2023). Available https://www.latestly.com/technology/who-cautions-against-the-usage-of-ai-chatbots-like-chatgpt-bard-in-healthcare-5131887.html .   [70] I.G. Cohen    What Should ChatGPT Mean for Bioethics?   2023   Available at: SSRN 4430100  Cohen, I. G. (2023). What Should ChatGPT Mean for Bioethics? Available at SSRN 4430100.  [71] M.F. Mridha  A.J. Keya  M.A. Hamid  M.M. Monowar  M.S. Rahman   A comprehensive review on fake news detection with deep learning   IEEE Access  9  2021  156151 156170  10.1109/ACCESS.2021.3129329   Mridha, M. F., Keya, A. J., Hamid, M. A., Monowar, M. M., & Rahman, M. S. (2021). A comprehensive review on fake news detection with deep learning. IEEE Access, 9, pp. 156151-156170. https://doi.org/10.1109/ACCESS.2021.3129329.  [72] N. Hajli  U. Saeed  M. Tajvidi  F. Shirazi   Social bots and the spread of disinformation in social media: the challenges of artificial intelligence   Br. J. Manag.  33  2022  1238 1253  10.1111/1467-8551.12554   Hajli, N., Saeed, U., Tajvidi, M., & Shirazi, F. (2022). Social bots and the spread of disinformation in social media: The challenges of artificial intelligence. British Journal of Management, 33, 1238-1253. https://doi.org/10.1111/1467-8551.12554  [73] R. Raman   Transparency in research: an analysis of ChatGPT usage acknowledgment by authors across disciplines and geographies   Account. Res.   2023  10.1080/08989621.2023.2273377   Raman, R.(2023) Transparency in research: An analysis of ChatGPT usage acknowledgment by authors across disciplines and geographies, Accountability in Research, DOI: 10.1080/08989621.2023.2273377  [74] A. Grünebaum  J. Chervenak  S.L. Pollet  A. Katz  F.A. Chervenak   The exciting potential for ChatGPT in obstetrics and gynecology   Am. J. Obstet. Gynecol.  228  6 2023  696 705    Grunebaum, A., Chervenak, J., Pollet, S. L., Katz, A., & Chervenak, F. A. (2023). The exciting potential for ChatGPT in obstetrics and gynecology. American Journal of Obstetrics and Gynecology, 228(6), 696-705.  [75] R. Klavans  K.W. Boyack   Research portfolio analysis and topic prominence   Journal of Informetrics  11  4 2017  1158 1174    Klavans, R., & Boyack, K. W. (2017). Research portfolio analysis and topic prominence. Journal of Informetrics, 11(4), 1158-1174  [76] S.B. Naeem  R. Bhatti   The Covid‐19 ‘infodemic’: a new front for information professionals   Health Inf. Libr. J.  37  3 2020  233 239    Naeem, S. B., & Bhatti, R. (2020). The Covid-19 ‘infodemic’: a new front for information professionals. Health Information & Libraries Journal, 37(3), 233-239.  [77] S. Vosoughi  D. Roy  S. Aral   The spread of true and false news online   Science  359  6380 2018  1146 1151    Vosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false news online. science, 359(6380), 1146-1151  [78] S. Lewandowsky  U.K. Ecker  J. Cook   Beyond misinformation: understanding and coping with the "post-truth" era   Journal of applied research in memory and cognition  6  4 2017  353 369    Lewandowsky, S., Ecker, U. K., & Cook, J. (2017). Beyond misinformation: Understanding and coping with the "post-truth" era. Journal of applied research in memory and cognition, 6(4), 353-369.  [79] D.A. Scheufele  N.M. Krause   Science audiences, misinformation, and fake news   Proc. Natl. Acad. Sci. USA  116  16 2019  7662 7669    Scheufele, D. A., & Krause, N. M. (2019). Science audiences, misinformation, and fake news. Proceedings of the National Academy of Sciences, 116(16), 7662-7669.  [80] M. He  Y. Zhang  L. Gong  Y. Zhou  X. Song  W. Zhu   Z. Zhang   Bibliometric analysis of hydrogen storage   Int. J. Hydrogen Energy  44  52 2019  28206 28226    He, M., Zhang, Y., Gong, L., Zhou, Y., Song, X., Zhu, W., ... & Zhang, Z. (2019). Bibliometric analysis of hydrogen storage. International Journal of Hydrogen Energy, 44(52), 28206-28226.  [81] D. Lazer  M. Baum  N. Grinberg  L. Friedland  K. Joseph  W. Hobbs  C. Mattsson   Combating Fake News: an Agenda for Research and Action   2017    Lazer, D., Baum, M., Grinberg, N., Friedland, L., Joseph, K., Hobbs, W., & Mattsson, C. (2017). Combating fake news: An agenda for research and action.  [82] O. Abu Arqoub  A. Abdulateef Elega  B. Efe Özad  H. Dwikat  F. Adedamola Oloyede   Mapping the scholarship of fake news research: a systematic review   Journal. Pract.  16  1 2022  56 86    Abu Arqoub, O., Abdulateef Elega, A., Efe Ozad, B., Dwikat, H., & Adedamola Oloyede, F. (2022). Mapping the scholarship of fake news research: A systematic review. Journalism Practice, 16(1), 56-86.          