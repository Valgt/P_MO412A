{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1         2         3         4         5         6         7    \\\n",
      "1  1.000000  0.497972  0.134061  0.065794  0.541140  0.183011  0.135995   \n",
      "2  0.497972  1.000000 -0.057346  0.058898  0.259512  0.223909  0.197520   \n",
      "3  0.134061 -0.057346  1.000000 -0.109140  0.348754 -0.053662  0.340687   \n",
      "4  0.065794  0.058898 -0.109140  1.000000  0.106825  0.234263 -0.007710   \n",
      "5  0.541140  0.259512  0.348754  0.106825  1.000000  0.129674  0.290657   \n",
      "\n",
      "        8         9         10   ...       789       790       791       792  \\\n",
      "1  0.164164  0.107141 -0.079068  ...  0.115910  0.223875  0.287844  0.028263   \n",
      "2  0.280954  0.205832  0.280593  ...  0.222299 -0.010720  0.192699  0.241937   \n",
      "3 -0.248189  0.371167 -0.230586  ...  0.214892  0.569593  0.355426  0.004944   \n",
      "4  0.372907  0.284071  0.253789  ...  0.344647  0.097781  0.125714  0.326580   \n",
      "5 -0.009174  0.209874 -0.115949  ...  0.082730  0.371860  0.385915  0.108855   \n",
      "\n",
      "        793       794       795       796       797       798  \n",
      "1  0.233962  0.378379  0.102254  0.257842  0.183128  0.398422  \n",
      "2  0.428970  0.105742  0.151240  0.234917  0.368605  0.479544  \n",
      "3 -0.146186  0.439295  0.369682  0.035443  0.077036  0.011448  \n",
      "4  0.275543  0.177673  0.112918  0.514405  0.288372  0.117327  \n",
      "5  0.327832  0.329015  0.352895  0.146464  0.121268  0.373284  \n",
      "\n",
      "[5 rows x 798 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Leer el CSV y establecer la primera columna como índice\n",
    "df = pd.read_csv('data/similarity_matrix2.csv', index_col=0)\n",
    "\n",
    "# Paso 2: Crear el diccionario de mapeo\n",
    "labels = df.index.tolist()\n",
    "mapping_dict = {label: idx for idx, label in enumerate(labels, start=1)}  # Empezamos en 1\n",
    "\n",
    "# Paso 3: Reemplazar las etiquetas con números\n",
    "df.rename(index=mapping_dict, inplace=True)\n",
    "df.rename(columns=mapping_dict, inplace=True)\n",
    "\n",
    "# Paso 4: Verificar el resultado\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   goal_id target_id                                             target  \\\n",
      "0        1       1.1  By 2030, eradicate extreme poverty for all peo...   \n",
      "1        1       1.2  By 2030, reduce at least by half the proportio...   \n",
      "2        1       1.3  Implement nationally appropriate social protec...   \n",
      "3        1       1.4  By 2030, ensure that all men and women, in par...   \n",
      "4        1       1.5  By 2030, build the resilience of the poor and ...   \n",
      "\n",
      "                         palabras_clave_concatenadas  \\\n",
      "0                       poor and vulnerable, poverty   \n",
      "1                                            poverty   \n",
      "2                      vulnerable, social protection   \n",
      "3  equal rights to economic resources, human righ...   \n",
      "4         vulnerable, poor and vulnerable, resilient   \n",
      "\n",
      "                           palabras_clave_procesadas  \n",
      "0                           poor vulnerable, poverty  \n",
      "1                                            poverty  \n",
      "2                      vulnerable, social protection  \n",
      "3  equal rights economic resources, human rights,...  \n",
      "4             vulnerable, poor vulnerable, resilient  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sgsr_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Descargar los 'stopwords' en inglés\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Leer el CSV\n",
    "df_targets = pd.read_csv('data/targets_con_palabras_clave_agrupadas.csv')\n",
    "\n",
    "# Obtener la lista de stopwords en inglés\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def procesar_palabras_clave(palabras_clave):\n",
    "    # Separar las frases por comas y eliminar espacios extra\n",
    "    frases = [frase.strip() for frase in palabras_clave.split(',')]\n",
    "    \n",
    "    frases_procesadas = []\n",
    "    for frase in frases:\n",
    "        # Convertir a minúsculas\n",
    "        frase = frase.lower()\n",
    "        \n",
    "        # Eliminar puntuación\n",
    "        frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Tokenizar la frase en palabras\n",
    "        palabras = frase.split()\n",
    "        \n",
    "        # Eliminar stopwords\n",
    "        palabras_filtradas = [palabra for palabra in palabras if palabra not in stop_words]\n",
    "        \n",
    "        # Unir las palabras filtradas de nuevo en una frase\n",
    "        frase_filtrada = ' '.join(palabras_filtradas)\n",
    "        \n",
    "        # Agregar la frase procesada a la lista\n",
    "        frases_procesadas.append(frase_filtrada)\n",
    "    \n",
    "    # Unir todas las frases procesadas en una cadena separada por comas\n",
    "    return ', '.join(frases_procesadas)\n",
    "\n",
    "# Aplicar la función a la columna y crear una nueva columna con los resultados\n",
    "df_targets['palabras_clave_procesadas'] = df_targets['palabras_clave_concatenadas'].apply(procesar_palabras_clave)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df_targets.head())\n",
    "\n",
    "# Nota: No se guarda el DataFrame modificado en un nuevo CSV según lo solicitado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV guardado en: data\\targets_con_palabras_clave_mapeadas.csv\n",
      "Palabras faltantes guardadas en: data\\missing_words.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Crear el directorio 'data' si no existe\n",
    "output_dir = 'data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def mapear_frases_a_indices(palabras_clave, mapping_dict, missing_words_set):\n",
    "    # Separar las frases por comas y eliminar espacios extra\n",
    "    frases = [frase.strip() for frase in palabras_clave.split(',')]\n",
    "    \n",
    "    indices = []\n",
    "    for frase in frases:\n",
    "        if frase in mapping_dict:\n",
    "            indices.append(str(mapping_dict[frase]))\n",
    "        else:\n",
    "            missing_words_set.add(frase)\n",
    "    \n",
    "    # Unir los índices en una cadena separada por comas\n",
    "    return ', '.join(indices)\n",
    "\n",
    "# Inicializar un conjunto para almacenar las palabras faltantes\n",
    "missing_words = set()\n",
    "\n",
    "# Aplicar la función a la columna y crear una nueva columna con los índices mapeados\n",
    "df_targets['indices_mapeados'] = df_targets['palabras_clave_procesadas'].apply(\n",
    "    lambda x: mapear_frases_a_indices(x, mapping_dict, missing_words)\n",
    ")\n",
    "\n",
    "# Definir la ruta para el archivo de palabras faltantes\n",
    "missing_words_file = os.path.join(output_dir, 'missing_words.txt')\n",
    "\n",
    "# Escribir las palabras faltantes en el archivo\n",
    "with open(missing_words_file, 'w', encoding='utf-8') as file:\n",
    "    for palabra in sorted(missing_words):\n",
    "        file.write(f\"{palabra}\\n\")\n",
    "\n",
    "# Definir la ruta para el archivo CSV final\n",
    "final_csv_path = os.path.join(output_dir, 'targets_con_palabras_clave_mapeadas.csv')\n",
    "\n",
    "# Guardar el DataFrame en el archivo CSV\n",
    "df_targets.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado en: {final_csv_path}\")\n",
    "print(f\"Palabras faltantes guardadas en: {missing_words_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>target</th>\n",
       "      <th>palabras_clave_concatenadas</th>\n",
       "      <th>palabras_clave_procesadas</th>\n",
       "      <th>indices_mapeados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>By 2030, eradicate extreme poverty for all peo...</td>\n",
       "      <td>poor and vulnerable, poverty</td>\n",
       "      <td>poor vulnerable, poverty</td>\n",
       "      <td>536, 275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>By 2030, reduce at least by half the proportio...</td>\n",
       "      <td>poverty</td>\n",
       "      <td>poverty</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Implement nationally appropriate social protec...</td>\n",
       "      <td>vulnerable, social protection</td>\n",
       "      <td>vulnerable, social protection</td>\n",
       "      <td>194, 720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>By 2030, ensure that all men and women, in par...</td>\n",
       "      <td>equal rights to economic resources, human righ...</td>\n",
       "      <td>equal rights economic resources, human rights,...</td>\n",
       "      <td>642, 583, 500, 45, 773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>By 2030, build the resilience of the poor and ...</td>\n",
       "      <td>vulnerable, poor and vulnerable, resilient</td>\n",
       "      <td>vulnerable, poor vulnerable, resilient</td>\n",
       "      <td>194, 536, 368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>17</td>\n",
       "      <td>17.15</td>\n",
       "      <td>Respect each country’s policy space and leader...</td>\n",
       "      <td>poverty eradication, development assistance, g...</td>\n",
       "      <td>poverty eradication, development assistance, g...</td>\n",
       "      <td>193, 667, 295, 293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>17</td>\n",
       "      <td>17.16</td>\n",
       "      <td>Enhance the global partnership for sustainable...</td>\n",
       "      <td>publicprivate partnerships, global partnership...</td>\n",
       "      <td>publicprivate partnerships, global partnership...</td>\n",
       "      <td>295, 335, 293, 623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>17</td>\n",
       "      <td>17.17</td>\n",
       "      <td>Encourage and promote effective public, public...</td>\n",
       "      <td>civil society partnerships</td>\n",
       "      <td>civil society partnerships</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17</td>\n",
       "      <td>17.18</td>\n",
       "      <td>By 2020, enhance capacity-building support to ...</td>\n",
       "      <td>least developed countries, small island develo...</td>\n",
       "      <td>least developed countries, small island develo...</td>\n",
       "      <td>16, 485, 293, 621, 740, 623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>17</td>\n",
       "      <td>17.19</td>\n",
       "      <td>By 2030, build on existing initiatives to deve...</td>\n",
       "      <td>capacity building, global partnership, sustain...</td>\n",
       "      <td>capacity building, global partnership, sustain...</td>\n",
       "      <td>668, 295, 293, 623, 747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     goal_id target_id                                             target  \\\n",
       "0          1       1.1  By 2030, eradicate extreme poverty for all peo...   \n",
       "1          1       1.2  By 2030, reduce at least by half the proportio...   \n",
       "2          1       1.3  Implement nationally appropriate social protec...   \n",
       "3          1       1.4  By 2030, ensure that all men and women, in par...   \n",
       "4          1       1.5  By 2030, build the resilience of the poor and ...   \n",
       "..       ...       ...                                                ...   \n",
       "164       17     17.15  Respect each country’s policy space and leader...   \n",
       "165       17     17.16  Enhance the global partnership for sustainable...   \n",
       "166       17     17.17  Encourage and promote effective public, public...   \n",
       "167       17     17.18  By 2020, enhance capacity-building support to ...   \n",
       "168       17     17.19  By 2030, build on existing initiatives to deve...   \n",
       "\n",
       "                           palabras_clave_concatenadas  \\\n",
       "0                         poor and vulnerable, poverty   \n",
       "1                                              poverty   \n",
       "2                        vulnerable, social protection   \n",
       "3    equal rights to economic resources, human righ...   \n",
       "4           vulnerable, poor and vulnerable, resilient   \n",
       "..                                                 ...   \n",
       "164  poverty eradication, development assistance, g...   \n",
       "165  publicprivate partnerships, global partnership...   \n",
       "166                         civil society partnerships   \n",
       "167  least developed countries, small island develo...   \n",
       "168  capacity building, global partnership, sustain...   \n",
       "\n",
       "                             palabras_clave_procesadas  \\\n",
       "0                             poor vulnerable, poverty   \n",
       "1                                              poverty   \n",
       "2                        vulnerable, social protection   \n",
       "3    equal rights economic resources, human rights,...   \n",
       "4               vulnerable, poor vulnerable, resilient   \n",
       "..                                                 ...   \n",
       "164  poverty eradication, development assistance, g...   \n",
       "165  publicprivate partnerships, global partnership...   \n",
       "166                         civil society partnerships   \n",
       "167  least developed countries, small island develo...   \n",
       "168  capacity building, global partnership, sustain...   \n",
       "\n",
       "                indices_mapeados  \n",
       "0                       536, 275  \n",
       "1                            275  \n",
       "2                       194, 720  \n",
       "3         642, 583, 500, 45, 773  \n",
       "4                  194, 536, 368  \n",
       "..                           ...  \n",
       "164           193, 667, 295, 293  \n",
       "165           295, 335, 293, 623  \n",
       "166                          526  \n",
       "167  16, 485, 293, 621, 740, 623  \n",
       "168      668, 295, 293, 623, 747  \n",
       "\n",
       "[169 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesado target 12.c (1/169)\n",
      "Procesado target 11.3 (2/169)\n",
      "Procesado target 5.2 (3/169)\n",
      "Procesado target 3.c (4/169)\n",
      "Procesado target 5.6 (5/169)\n",
      "Procesado target 17.16 (6/169)\n",
      "Procesado target 15.6 (7/169)\n",
      "Procesado target 17.5 (8/169)\n",
      "Procesado target 4.a (9/169)\n",
      "Procesado target 15.c (10/169)\n",
      "Procesado target 4.b (11/169)\n",
      "Procesado target 16.9 (12/169)\n",
      "Procesado target 1.a (13/169)\n",
      "Procesado target 16.6 (14/169)\n",
      "Procesado target 6.6 (15/169)\n",
      "Procesado target 11.2 (16/169)\n",
      "Procesado target 12.5 (17/169)\n",
      "Procesado target 17.19 (18/169)\n",
      "Procesado target 9.5 (19/169)\n",
      "Procesado target 16.1 (20/169)\n",
      "Procesado target 17.3 (21/169)\n",
      "Procesado target 9.c (22/169)\n",
      "Procesado target 10.6 (23/169)\n",
      "Procesado target 14.4 (24/169)\n",
      "Procesado target 10.a (25/169)\n",
      "Procesado target 15.3 (26/169)\n",
      "Procesado target 13.1 (27/169)\n",
      "Procesado target 16.2 (28/169)\n",
      "Procesado target 17.12 (29/169)\n",
      "Procesado target 17.15 (30/169)\n",
      "Procesado target 13.2 (31/169)\n",
      "Procesado target 14.3 (32/169)\n",
      "Procesado target 17.13 (33/169)\n",
      "Procesado target 1.3 (34/169)\n",
      "Procesado target 4.6 (35/169)\n",
      "Procesado target 13.b (36/169)\n",
      "Procesado target 6.4 (37/169)\n",
      "Procesado target 9.4 (38/169)\n",
      "Procesado target 15.7 (39/169)\n",
      "Procesado target 10.c (40/169)\n",
      "Procesado target 9.2 (41/169)\n",
      "Procesado target 15.4 (42/169)\n",
      "Procesado target 15.5 (43/169)\n",
      "Procesado target 8.b (44/169)\n",
      "Procesado target 16.4 (45/169)\n",
      "Procesado target 12.8 (46/169)\n",
      "Procesado target 16.5 (47/169)\n",
      "Procesado target 3.1 (48/169)\n",
      "Procesado target 6.3 (49/169)\n",
      "Procesado target 13.a (50/169)\n",
      "Procesado target 3.a (51/169)\n",
      "Procesado target 8.3 (52/169)\n",
      "Procesado target 1.1 (53/169)\n",
      "Procesado target 3.4 (54/169)\n",
      "Procesado target 17.11 (55/169)\n",
      "Procesado target 4.2 (56/169)\n",
      "Procesado target 2.b (57/169)\n",
      "Procesado target 14.7 (58/169)\n",
      "Procesado target 7.a (59/169)\n",
      "Procesado target 12.6 (60/169)\n",
      "Procesado target 17.2 (61/169)\n",
      "Procesado target 4.4 (62/169)\n",
      "Procesado target 7.b (63/169)\n",
      "Procesado target 8.9 (64/169)\n",
      "Procesado target 10.7 (65/169)\n",
      "Procesado target 12.2 (66/169)\n",
      "Procesado target 13.3 (67/169)\n",
      "Procesado target 3.9 (68/169)\n",
      "Procesado target 16.10 (69/169)\n",
      "Procesado target 3.d (70/169)\n",
      "Procesado target 9.b (71/169)\n",
      "Procesado target 10.1 (72/169)\n",
      "Procesado target 11.6 (73/169)\n",
      "Procesado target 14.a (74/169)\n",
      "Procesado target 11.1 (75/169)\n",
      "Procesado target 15.a (76/169)\n",
      "Procesado target 5.1 (77/169)\n",
      "Procesado target 17.18 (78/169)\n",
      "Procesado target 14.c (79/169)\n",
      "Procesado target 1.b (80/169)\n",
      "Procesado target 9.1 (81/169)\n",
      "Procesado target 8.10 (82/169)\n",
      "Procesado target 1.2 (83/169)\n",
      "Procesado target 5.4 (84/169)\n",
      "Procesado target 2.a (85/169)\n",
      "Procesado target 12.4 (86/169)\n",
      "Procesado target 15.1 (87/169)\n",
      "Procesado target 10.3 (88/169)\n",
      "Procesado target 15.9 (89/169)\n",
      "Procesado target 4.c (90/169)\n",
      "Procesado target 7.1 (91/169)\n",
      "Procesado target 15.8 (92/169)\n",
      "Procesado target 3.2 (93/169)\n",
      "Procesado target 10.b (94/169)\n",
      "Procesado target 8.4 (95/169)\n",
      "Procesado target 4.7 (96/169)\n",
      "Procesado target 3.5 (97/169)\n",
      "Procesado target 8.8 (98/169)\n",
      "Procesado target 5.3 (99/169)\n",
      "Procesado target 6.2 (100/169)\n",
      "Procesado target 14.b (101/169)\n",
      "Procesado target 11.5 (102/169)\n",
      "Procesado target 10.5 (103/169)\n",
      "Procesado target 16.3 (104/169)\n",
      "Procesado target 12.1 (105/169)\n",
      "Procesado target 10.4 (106/169)\n",
      "Procesado target 3.b (107/169)\n",
      "Procesado target 11.a (108/169)\n",
      "Procesado target 17.6 (109/169)\n",
      "Procesado target 3.7 (110/169)\n",
      "Procesado target 2.2 (111/169)\n",
      "Procesado target 6.a (112/169)\n",
      "Procesado target 16.8 (113/169)\n",
      "Procesado target 8.2 (114/169)\n",
      "Procesado target 10.2 (115/169)\n",
      "Procesado target 6.1 (116/169)\n",
      "Procesado target 17.9 (117/169)\n",
      "Procesado target 16.7 (118/169)\n",
      "Procesado target 7.2 (119/169)\n",
      "Procesado target 12.7 (120/169)\n",
      "Procesado target 1.4 (121/169)\n",
      "Procesado target 8.5 (122/169)\n",
      "Procesado target 12.b (123/169)\n",
      "Procesado target 8.7 (124/169)\n",
      "Procesado target 8.1 (125/169)\n",
      "Procesado target 2.3 (126/169)\n",
      "Procesado target 14.6 (127/169)\n",
      "Procesado target 9.3 (128/169)\n",
      "Procesado target 15.b (129/169)\n",
      "Procesado target 17.8 (130/169)\n",
      "Procesado target 14.2 (131/169)\n",
      "Procesado target 17.10 (132/169)\n",
      "Procesado target 2.4 (133/169)\n",
      "Procesado target 8.a (134/169)\n",
      "Procesado target 11.4 (135/169)\n",
      "Procesado target 3.3 (136/169)\n",
      "Procesado target 14.1 (137/169)\n",
      "Procesado target 9.a (138/169)\n",
      "Procesado target 15.2 (139/169)\n",
      "Procesado target 16.b (140/169)\n",
      "Procesado target 5.5 (141/169)\n",
      "Procesado target 3.6 (142/169)\n",
      "Procesado target 3.8 (143/169)\n",
      "Procesado target 8.6 (144/169)\n",
      "Procesado target 11.b (145/169)\n",
      "Procesado target 12.3 (146/169)\n",
      "Procesado target 7.3 (147/169)\n",
      "Procesado target 17.14 (148/169)\n",
      "Procesado target 1.5 (149/169)\n",
      "Procesado target 2.c (150/169)\n",
      "Procesado target 17.4 (151/169)\n",
      "Procesado target 5.c (152/169)\n",
      "Procesado target 6.5 (153/169)\n",
      "Procesado target 4.3 (154/169)\n",
      "Procesado target 4.5 (155/169)\n",
      "Procesado target 14.5 (156/169)\n",
      "Procesado target 6.b (157/169)\n",
      "Procesado target 16.a (158/169)\n",
      "Procesado target 17.1 (159/169)\n",
      "Procesado target 17.17 (160/169)\n",
      "Procesado target 4.1 (161/169)\n",
      "Procesado target 2.5 (162/169)\n",
      "Procesado target 17.7 (163/169)\n",
      "Procesado target 11.c (164/169)\n",
      "Procesado target 11.7 (165/169)\n",
      "Procesado target 12.a (166/169)\n",
      "Procesado target 5.b (167/169)\n",
      "Procesado target 2.1 (168/169)\n",
      "Procesado target 5.a (169/169)\n",
      "\n",
      "DataFrame de Grafos de Similitud:\n",
      "          12.c      11.3       5.2       3.c       5.6     17.16      15.6  \\\n",
      "12.c  0.471157  0.288604  0.181136  0.356676  0.070167  0.340515  0.324503   \n",
      "11.3  0.288604  0.626167  0.245340  0.320303  0.219582  0.301334  0.309093   \n",
      "5.2   0.181136  0.245340  0.602815  0.241081  0.513788  0.172140  0.208478   \n",
      "3.c   0.356676  0.320303  0.241081  0.606920  0.253806  0.397669  0.278567   \n",
      "5.6   0.070167  0.219582  0.513788  0.253806  0.894382  0.216603  0.233830   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "11.7 -0.051049  0.135906  0.518793  0.140677  0.633667 -0.061134 -0.082485   \n",
      "12.a  0.410402  0.331569  0.140178  0.376617  0.093179  0.419297  0.353366   \n",
      "5.b   0.150511  0.230376  0.680044  0.275604  0.602252  0.231025  0.171018   \n",
      "2.1   0.285428  0.193871  0.262670  0.219242  0.287765  0.193883  0.197653   \n",
      "5.a   0.256297  0.312660  0.499414  0.284946  0.628019  0.346241  0.408192   \n",
      "\n",
      "          17.5       4.a      15.c  ...     17.17       4.1       2.5  \\\n",
      "12.c  0.380087  0.060706  0.151893  ...  0.223965  0.197244  0.181757   \n",
      "11.3  0.263914  0.174066  0.342536  ...  0.166757  0.228671  0.278818   \n",
      "5.2   0.177802  0.412432  0.250918  ...  0.249490  0.368654  0.319252   \n",
      "3.c   0.688682  0.180377  0.224149  ...  0.257401  0.251924  0.170301   \n",
      "5.6   0.152561  0.538897  0.172494  ...  0.418515  0.497021  0.331503   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "11.7  0.002219  0.631627  0.155482  ...  0.126941  0.325257  0.242478   \n",
      "12.a  0.431923  0.061912  0.155625  ...  0.233706  0.230468  0.187356   \n",
      "5.b   0.231279  0.546466  0.117188  ...  0.393771  0.576869  0.282815   \n",
      "2.1   0.181392  0.194742  0.234355  ...  0.169395  0.253719  0.303794   \n",
      "5.a   0.253435  0.411857  0.226211  ...  0.424273  0.505533  0.408402   \n",
      "\n",
      "          17.7      11.c      11.7      12.a       5.b       2.1       5.a  \n",
      "12.c  0.387298  0.352109 -0.051049  0.410402  0.150511  0.285428  0.256297  \n",
      "11.3  0.256366  0.393522  0.135906  0.331569  0.230376  0.193871  0.312660  \n",
      "5.2   0.149481  0.148618  0.518793  0.140178  0.680044  0.262670  0.499414  \n",
      "3.c   0.437422  0.418242  0.140677  0.376617  0.275604  0.219242  0.284946  \n",
      "5.6   0.131368  0.084412  0.633667  0.093179  0.602252  0.287765  0.628019  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "11.7 -0.126129 -0.090165  1.000000 -0.097198  0.590393  0.183518  0.382645  \n",
      "12.a  0.415344  0.416444 -0.097198  0.506536  0.114004  0.230789  0.274364  \n",
      "5.b   0.157311  0.169891  0.590393  0.114004  0.989901  0.239707  0.575019  \n",
      "2.1   0.227905  0.250810  0.183518  0.230789  0.239707  0.738127  0.296543  \n",
      "5.a   0.273024  0.270333  0.382645  0.274364  0.575019  0.296543  0.726007  \n",
      "\n",
      "[169 rows x 169 columns]\n",
      "\n",
      "Nuevo DataFrame guardado en: data\\nuevo_dataframe.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Asegúrate de haber leído previamente tus DataFrames:\n",
    "# df_similarity: Matriz de similitud mapeada\n",
    "# df_targets: DataFrame con 'target_id' y 'indices_mapeados'\n",
    "\n",
    "# Supongamos que ya has leído y procesado los DataFrames como en los pasos anteriores\n",
    "# df_similarity = pd.read_csv('similarity_matrix2.csv', index_col=0)\n",
    "# df_targets = pd.read_csv('data/targets_con_palabras_clave_mapeadas.csv')\n",
    "\n",
    "# Asegúrate de que los índices de df_similarity sean enteros\n",
    "df.index = df.index.astype(int)\n",
    "df.columns = df.columns.astype(int)\n",
    "\n",
    "# Obtener la lista única de targets\n",
    "target_list = list(set(df_targets['target_id'].tolist()))\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los resultados\n",
    "df_graph = pd.DataFrame(index=target_list, columns=target_list, dtype=float)\n",
    "\n",
    "# Función para convertir la cadena de índices a una lista de enteros\n",
    "def convertir_indices(ind_str):\n",
    "    if pd.isna(ind_str):\n",
    "        return []\n",
    "    return [int(x.strip()) for x in ind_str.split(',')]\n",
    "\n",
    "# Iterar sobre cada par de targets\n",
    "for tg1 in target_list:\n",
    "    # Obtener los índices para tg1\n",
    "    ind1_str = df_targets[df_targets['target_id'] == tg1]['indices_mapeados'].values\n",
    "    ind1 = convertir_indices(ind1_str[0]) if len(ind1_str) > 0 else []\n",
    "    \n",
    "    for tg2 in target_list:\n",
    "        # Obtener los índices para tg2\n",
    "        ind2_str = df_targets[df_targets['target_id'] == tg2]['indices_mapeados'].values\n",
    "        ind2 = convertir_indices(ind2_str[0]) if len(ind2_str) > 0 else []\n",
    "        \n",
    "        # Inicializar suma y contador\n",
    "        suma_similitudes = 0\n",
    "        total_pares = 0\n",
    "        \n",
    "        # Calcular la suma de las similitudes para todos los pares de índices\n",
    "        for x1 in ind1:\n",
    "            for x2 in ind2:\n",
    "                if x1 in df.index and x2 in df.columns:\n",
    "                    suma_similitudes += df.loc[x1, x2]\n",
    "                    total_pares += 1\n",
    "                else:\n",
    "                    print(f\"Advertencia: Índices {x1} o {x2} no existen en la matriz de similitud.\")\n",
    "        \n",
    "        # Calcular el promedio si hay al menos un par\n",
    "        if total_pares > 0:\n",
    "            promedio = suma_similitudes / total_pares\n",
    "        else:\n",
    "            promedio = np.nan  # O puedes asignar otro valor por defecto, como 0\n",
    "        \n",
    "        # Asignar el promedio al DataFrame\n",
    "        df_graph.loc[tg1, tg2] = promedio\n",
    "\n",
    "    # Opcional: Imprimir progreso\n",
    "    print(f\"Procesado target {tg1} ({target_list.index(tg1)+1}/{len(target_list)})\")\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(\"\\nDataFrame de Grafos de Similitud:\")\n",
    "print(df_graph)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "output_dir = 'data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "final_csv_path_graph = os.path.join(output_dir, 'nuevo_dataframe.csv')\n",
    "df_graph.to_csv(final_csv_path_graph)\n",
    "\n",
    "print(f\"\\nNuevo DataFrame guardado en: {final_csv_path_graph}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
