{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han extraído 33 líneas con 5 palabras o más a 'textos_filtrados_all.txt'\n",
      "Se han extraído 41 oraciones con más de 10 palabras a 'textos_filtrados_20_split.txt'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "def contar_palabras(texto):\n",
    "    \"\"\"Cuenta el número de palabras en una cadena de texto.\"\"\"\n",
    "    return len(re.findall(r'\\b\\w+\\b', texto)) if texto else 0\n",
    "\n",
    "def eliminar_enlaces(texto):\n",
    "    \"\"\"Elimina URLs del texto.\"\"\"\n",
    "    url_pattern = r'http\\S+|www\\.\\S+'\n",
    "    return re.sub(url_pattern, '', texto)\n",
    "\n",
    "def eliminar_nonsense(texto):\n",
    "    \"\"\"Elimina patrones no deseados como timestamps, DOIs, ISBNs, filenames con extensiones y avisos de copyright.\"\"\"\n",
    "    # Eliminar timestamps como 2019-07-03T03:21:42.840889Z\n",
    "    timestamp_pattern = fr'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z?'\n",
    "    texto = re.sub(timestamp_pattern, '', texto)\n",
    "    \n",
    "    # Eliminar DOIs, con o sin 'doi:'\n",
    "    doi_pattern = r'\\b(?:doi:)?10\\.\\d{4,9}/[-._;()/:A-Z0-9]+\\b'\n",
    "    texto = re.sub(doi_pattern, '', texto, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Eliminar ISBNs, con o sin 'urn:isbn:'\n",
    "    isbn_pattern = r'\\b(?:urn:isbn:)?(?:97[89]-)?\\d{1,5}-\\d{2,7}-\\d{2,7}-\\d\\b'\n",
    "    texto = re.sub(isbn_pattern, '', texto, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Eliminar códigos similares como \"B978-0-08-100596-5.22063-5\", \"10.1016/C2016-1-03722-7\"\n",
    "    other_patterns = r'\\b[A-Z]?\\d{4}-\\d{2}-\\d{2,}-\\d{1,}\\b'\n",
    "    texto = re.sub(other_patterns, '', texto)\n",
    "    \n",
    "    # Eliminar filenames con extensiones (e.g., 3-s2.0-B9780081026717107018-f701-01-9780081026717.sml)\n",
    "    filename_pattern = r'\\b\\w+\\.(?:png|jpg|jpeg|gif|bmp|pdf|docx?|xlsx?|sml)\\b'\n",
    "    texto = re.sub(filename_pattern, '', texto, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Eliminar avisos de copyright\n",
    "    copyright_pattern = r'\\bCopyright\\s?©\\b.*'\n",
    "    texto = re.sub(copyright_pattern, '', texto, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Eliminar múltiples espacios\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    \n",
    "    return texto.strip()\n",
    "\n",
    "def eliminar_referencias(texto):\n",
    "    \"\"\"Elimina líneas que contienen 'et al' y tienen menos de 7 palabras.\"\"\"\n",
    "    if 'et al' in texto.lower() and contar_palabras(texto) < 7:\n",
    "        return None\n",
    "    return texto\n",
    "\n",
    "def eliminar_logo_copyright(texto):\n",
    "    \"\"\"Elimina líneas que contienen símbolos de copyright.\"\"\"\n",
    "    if re.search(r'\\(c\\)|©', texto):\n",
    "        return None\n",
    "    return texto\n",
    "\n",
    "def tiene_demasiados_caracteres_especiales(texto, porcentaje=0.1):\n",
    "    \"\"\"Elimina líneas donde más del porcentaje de caracteres son especiales.\"\"\"\n",
    "    if not texto:\n",
    "        return False\n",
    "    especiales = re.findall(r'[.,()\\-]', texto)\n",
    "    return len(especiales) / len(texto) > porcentaje\n",
    "\n",
    "# Ruta del archivo XML\n",
    "archivo_entrada = 'articulos/10.1016_B978-0-08-100596-5.22063-5.xml'\n",
    "archivo_salida_all = 'textos_filtrados_all.txt'\n",
    "archivo_salida_20 = 'textos_filtrados_20_split.txt'\n",
    "\n",
    "# Parsear el XML\n",
    "tree = etree.parse(archivo_entrada)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Conjunto para almacenar textos filtrados y eliminar duplicados\n",
    "textos_filtrados = set()\n",
    "textos_filtrados_20_split = set()\n",
    "\n",
    "# Iterar sobre todos los elementos, excluyendo los que contienen 'author' en su etiqueta\n",
    "for elem in root.iter():\n",
    "    if 'author' in elem.tag.lower():\n",
    "        continue  # Ignorar elementos relacionados con autores\n",
    "    texto = elem.text\n",
    "    if texto:\n",
    "        # Eliminar enlaces\n",
    "        texto_sin_enlaces = eliminar_enlaces(texto.strip())\n",
    "        # Eliminar patrones no deseados\n",
    "        texto_limpio = eliminar_nonsense(texto_sin_enlaces)\n",
    "        # Eliminar referencias no deseadas\n",
    "        texto_final = eliminar_referencias(texto_limpio)\n",
    "        if texto_final:\n",
    "            # Eliminar líneas con demasiados caracteres especiales\n",
    "            if not tiene_demasiados_caracteres_especiales(texto_final):\n",
    "                # Eliminar líneas que contienen copyright\n",
    "                texto_final = eliminar_logo_copyright(texto_final)\n",
    "                if texto_final:\n",
    "                    num_palabras = contar_palabras(texto_final)\n",
    "                    # Filtrar textos con 5 palabras o más\n",
    "                    if num_palabras >= 5:\n",
    "                        textos_filtrados.add(texto_final)\n",
    "                        # Para textos con más de 20 palabras, realizar el split\n",
    "                        if num_palabras > 20:\n",
    "                            # Dividir por puntos\n",
    "                            oraciones = texto_final.split('.')\n",
    "                            for oracion in oraciones:\n",
    "                                oracion = oracion.strip()\n",
    "                                if contar_palabras(oracion) > 10:\n",
    "                                    textos_filtrados_20_split.add(oracion)\n",
    "\n",
    "# Guardar todos los textos filtrados en 'textos_filtrados_all.txt'\n",
    "with open(archivo_salida_all, 'w', encoding='utf-8') as f_all:\n",
    "    for linea in textos_filtrados:\n",
    "        f_all.write(linea + '\\n')\n",
    "\n",
    "# Guardar las oraciones filtradas en 'textos_filtrados_20_split.txt'\n",
    "with open(archivo_salida_20, 'w', encoding='utf-8') as f_20:\n",
    "    for linea in textos_filtrados_20_split:\n",
    "        f_20.write(linea + '\\n')\n",
    "\n",
    "# Contar las líneas\n",
    "total_all = len(textos_filtrados)\n",
    "total_20 = len(textos_filtrados_20_split)\n",
    "\n",
    "print(f\"Se han extraído {total_all} líneas con 5 palabras o más a '{archivo_salida_all}'\")\n",
    "print(f\"Se han extraído {total_20} oraciones con más de 10 palabras a '{archivo_salida_20}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-5.3.0-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 12.1 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-5.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p_mo412a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
